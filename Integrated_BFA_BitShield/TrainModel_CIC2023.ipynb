{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f44d3b7-0ac2-4d07-ab06-c2cdf178a6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 18:15:51.779399: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764180951.797508 1724256 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764180951.803667 1724256 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764180951.819863 1724256 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764180951.819889 1724256 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764180951.819890 1724256 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764180951.819892 1724256 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-26 18:15:51.824322: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os, sys, random\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.datasets as dsetẢ\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import math\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab1743d-1201-4bb2-b74c-1c6b1e0979a0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class RecorderMeter(object):\n",
    "    \"\"\"Computes and stores the minimum loss value and its epoch index, along with MCC\"\"\"\n",
    "\n",
    "    def __init__(self, total_epoch):\n",
    "        self.reset(total_epoch)\n",
    "\n",
    "    def reset(self, total_epoch):\n",
    "        assert total_epoch > 0\n",
    "        self.total_epoch = total_epoch\n",
    "        self.current_epoch = 0\n",
    "        self.epoch_losses = np.zeros((self.total_epoch, 2), dtype=np.float32)  # [epoch, train/val]\n",
    "        self.epoch_losses = self.epoch_losses - 1\n",
    "\n",
    "        self.epoch_mcc = np.zeros((self.total_epoch, 2), dtype=np.float32)  # [epoch, train/val]\n",
    "        self.epoch_mcc = self.epoch_mcc\n",
    "\n",
    "    def update(self, idx, train_loss, train_mcc, val_loss, val_mcc):\n",
    "        assert idx >= 0 and idx < self.total_epoch, 'total_epoch : {} , but update with the {} index'.format(\n",
    "            self.total_epoch, idx)\n",
    "        self.epoch_losses[idx, 0] = train_loss\n",
    "        self.epoch_losses[idx, 1] = val_loss\n",
    "        self.epoch_mcc[idx, 0] = train_mcc\n",
    "        self.epoch_mcc[idx, 1] = val_mcc\n",
    "        self.current_epoch = idx + 1\n",
    "\n",
    "    def max_mcc(self, istrain):\n",
    "        if self.current_epoch <= 0:\n",
    "            return 0\n",
    "        if istrain:\n",
    "            return self.epoch_mcc[:self.current_epoch, 0].max()\n",
    "        else:\n",
    "            return self.epoch_mcc[:self.current_epoch, 1].max()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d94f3b-6448-4cc4-8909-784cdfc88190",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def time_string():\n",
    "    ISOTIMEFORMAT = '%Y-%m-%d %X'\n",
    "    string = '[{}]'.format(\n",
    "        time.strftime(ISOTIMEFORMAT, time.gmtime(time.time())))\n",
    "    return string\n",
    "\n",
    "\n",
    "def convert_secs2time(epoch_time):\n",
    "    need_hour = int(epoch_time / 3600)\n",
    "    need_mins = int((epoch_time - 3600 * need_hour) / 60)\n",
    "    need_secs = int(epoch_time - 3600 * need_hour - 60 * need_mins)\n",
    "    return need_hour, need_mins, need_secs\n",
    "\n",
    "\n",
    "def time_file_str():\n",
    "    ISOTIMEFORMAT = '%Y-%m-%d'\n",
    "    string = '{}'.format(time.strftime(ISOTIMEFORMAT,\n",
    "                                       time.gmtime(time.time())))\n",
    "    return string + '-{}'.format(random.randint(1, 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebfc21f-f070-4c3a-9d14-0016ff758cdf",
   "metadata": {},
   "source": [
    "### Class quan_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5d955bd-6a8c-4182-8406-0edb3d399df1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class quan_Linear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(quan_Linear, self).__init__(in_features, out_features, bias=bias)\n",
    "\n",
    "        self.N_bits = 8\n",
    "        self.full_lvls = 2**self.N_bits\n",
    "        self.half_lvls = (self.full_lvls - 2) / 2\n",
    "        # Initialize the step size\n",
    "        self.step_size = nn.Parameter(torch.Tensor([1]), requires_grad=True)\n",
    "        self.__reset_stepsize__()\n",
    "        # flag to enable the inference with quantized weight or self.weight\n",
    "        self.inf_with_weight = False  # disabled by default\n",
    "\n",
    "        # create a vector to identify the weight to each bit\n",
    "        self.b_w = nn.Parameter(2**torch.arange(start=self.N_bits - 1,\n",
    "                                                end=-1,\n",
    "                                                step=-1).unsqueeze(-1).float(),\n",
    "                                requires_grad=False)\n",
    "\n",
    "        self.b_w[0] = -self.b_w[0]  #in-place reverse\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.inf_with_weight:\n",
    "            return F.linear(input, self.weight * self.step_size, self.bias)\n",
    "        else:\n",
    "            self.__reset_stepsize__()\n",
    "            weight_quan = quantize(self.weight, self.step_size,\n",
    "                                   self.half_lvls) * self.step_size\n",
    "            return F.linear(input, weight_quan, self.bias)\n",
    "\n",
    "    def __reset_stepsize__(self):\n",
    "        with torch.no_grad():\n",
    "            self.step_size.data = self.weight.abs().max() / self.half_lvls\n",
    "\n",
    "    def __reset_weight__(self):\n",
    "        '''\n",
    "        This function will reconstruct the weight stored in self.weight.\n",
    "        Replacing the orginal floating-point with the quantized fix-point\n",
    "        weight representation.\n",
    "        '''\n",
    "        # replace the weight with the quantized version\n",
    "        with torch.no_grad():\n",
    "            self.weight.data = quantize(self.weight, self.step_size,\n",
    "                                        self.half_lvls)\n",
    "        # enable the flag, thus now computation does not invovle weight quantization\n",
    "        self.inf_with_weight = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511ef91d-ed9d-4cc0-8e3e-871496baa077",
   "metadata": {},
   "source": [
    "### Class quan_Conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e7af0b0-250e-40d1-a1e5-8c4dc2c0edee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class quan_Conv1d(nn.Conv1d):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride=1,\n",
    "                 padding=1,\n",
    "                 dilation=1,\n",
    "                 groups=1,\n",
    "                 bias=True):\n",
    "        super(quan_Conv1d, self).__init__(in_channels,\n",
    "                                          out_channels,\n",
    "                                          kernel_size,\n",
    "                                          stride=stride,\n",
    "                                          padding=padding,\n",
    "                                          dilation=dilation,\n",
    "                                          groups=groups,\n",
    "                                          bias=bias)\n",
    "\n",
    "        # Số lượng bit để lượng tử hóa trọng số\n",
    "        self.N_bits = 8\n",
    "        self.full_lvls = 2 ** self.N_bits\n",
    "        self.half_lvls = (self.full_lvls - 2) / 2\n",
    "\n",
    "        # Bước lượng tử hóa (step size), là một tham số có thể học được\n",
    "        self.step_size = nn.Parameter(torch.Tensor([1]), requires_grad=True)\n",
    "        self.__reset_stepsize__()\n",
    "\n",
    "        # Cờ để bật hoặc tắt sử dụng trọng số lượng tử hóa\n",
    "        self.inf_with_weight = False  # Tắt theo mặc định\n",
    "\n",
    "        # Tạo một vector để biểu diễn trọng số cho từng bit\n",
    "        self.b_w = nn.Parameter(2 ** torch.arange(start=self.N_bits - 1,\n",
    "                                                  end=-1,\n",
    "                                                  step=-1).unsqueeze(-1).float(),\n",
    "                                requires_grad=False)\n",
    "        self.b_w[0] = -self.b_w[0]  # Biến đổi MSB thành giá trị âm để hỗ trợ bù hai\n",
    "\n",
    "    def __reset_stepsize__(self):\n",
    "        \"\"\"Hàm này dùng để đặt lại giá trị `step_size`.\"\"\"\n",
    "        # Giá trị này có thể được tùy chỉnh tùy thuộc vào yêu cầu của mô hình\n",
    "        self.step_size.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Kiểm tra cờ `inf_with_weight` để quyết định sử dụng trọng số đã lượng tử hóa hay không\n",
    "        if self.inf_with_weight:\n",
    "            quantized_weight = self.quantize_weight(self.weight)\n",
    "            return nn.functional.conv1d(x, quantized_weight, self.bias, self.stride,\n",
    "                                        self.padding, self.dilation, self.groups)\n",
    "        else:\n",
    "            return nn.functional.conv1d(x, self.weight, self.bias, self.stride,\n",
    "                                        self.padding, self.dilation, self.groups)\n",
    "\n",
    "    def quantize_weight(self, weight):\n",
    "        \"\"\"Lượng tử hóa trọng số theo số bit đã định.\"\"\"\n",
    "        # Tạo trọng số lượng tử hóa bằng cách sử dụng step_size\n",
    "        quantized_weight = torch.round(weight / self.step_size) * self.step_size\n",
    "        quantized_weight = torch.clamp(quantized_weight, -self.half_lvls * self.step_size,\n",
    "                                       (self.half_lvls - 1) * self.step_size)\n",
    "        return quantized_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa88fb5-bb55-4533-a756-13cbd6a6c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_quan_bitwidth(model, n_bit):\n",
    "    '''This script change the quantization bit-width of entire model to n_bit'''\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, quan_Conv1d) or isinstance(m, quan_Linear):\n",
    "            m.N_bits = n_bit\n",
    "            # print(\"Change weight bit-width as {}.\".format(m.N_bits))\n",
    "            m.b_w.data = m.b_w.data[-m.N_bits:]\n",
    "            m.b_w[0] = -m.b_w[0]\n",
    "            print(m.b_w)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa75564-0034-4b5e-9d74-bdd47ab945f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _quantize_func(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, step_size, half_lvls):\n",
    "        # ctx is a context object that can be used to stash information\n",
    "        # for backward computation\n",
    "        ctx.step_size = step_size\n",
    "        ctx.half_lvls = half_lvls\n",
    "        output = F.hardtanh(input,\n",
    "                            min_val=-ctx.half_lvls * ctx.step_size.item(),\n",
    "                            max_val=ctx.half_lvls * ctx.step_size.item())\n",
    "\n",
    "        output = torch.round(output / ctx.step_size)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_input = grad_output.clone() / ctx.step_size\n",
    "\n",
    "        return grad_input, None, None\n",
    "\n",
    "quantize = _quantize_func.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d00dfb4e-6a31-4c77-80fd-5f3c446e2172",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _bin_func(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, mu):\n",
    "        ctx.mu = mu\n",
    "        output = input.clone().zero_()\n",
    "        output[input.ge(0)] = 1\n",
    "        output[input.lt(0)] = -1\n",
    "\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_input = grad_output.clone() / ctx.mu\n",
    "        return grad_input, None\n",
    "\n",
    "w_bin = _bin_func.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f06e03c-27bb-4119-a6b7-785167405267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(tensor, step_size, half_lvls):\n",
    "    \"\"\"Quantization function.\"\"\"\n",
    "    return torch.clamp(torch.round(tensor / step_size), min=-half_lvls, max=half_lvls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ffdeb-6fac-47a8-b893-220f06d0200f",
   "metadata": {},
   "source": [
    "### Class CustomBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86a72a2a-9140-440b-9fec-b84050b902dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True, apply_softmax=False):\n",
    "        super(CustomBlock, self).__init__()\n",
    "        self.N_bits = 16\n",
    "        self.full_lvls = 2 ** self.N_bits\n",
    "        self.half_lvls = (self.full_lvls - 2) / 2\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        # Initialize the step size\n",
    "        self.step_size = nn.Parameter(torch.Tensor([1]), requires_grad=True)\n",
    "\n",
    "        # Initialize weights and bias\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_features)) if bias else None\n",
    "\n",
    "        # Reset parameters\n",
    "        self.__reset_stepsize__()\n",
    "        self.reset_parameters()\n",
    "\n",
    "        # Flag for inference with quantized weights\n",
    "        self.inf_with_weight = False\n",
    "\n",
    "        self.b_w = nn.Parameter(2**torch.arange(start=self.N_bits - 1,\n",
    "                                             end=-1,\n",
    "                                             step=-1).unsqueeze(-1).float(),\n",
    "                           requires_grad=False)\n",
    "        self.b_w[0] = -self.b_w[0]  #in-place reverse\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=5 ** 0.5)\n",
    "        if self.bias is not None:\n",
    "            nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.inf_with_weight:\n",
    "            weight_applied = self.weight * self.step_size\n",
    "        else:\n",
    "            self.__reset_stepsize__()\n",
    "            weight_quan = quantize(self.weight, self.step_size, self.half_lvls) * self.step_size\n",
    "            weight_applied = weight_quan\n",
    "\n",
    "        # Linear transformation\n",
    "        input = input.view(input.size(0), -1)  # Flatten input to 2D for matmul\n",
    "        output = input @ weight_applied.T\n",
    "        if self.bias is not None:\n",
    "            output += self.bias\n",
    "\n",
    "        if self.apply_softmax:\n",
    "            output = F.softmax(output, dim=-1)\n",
    "        return output\n",
    "\n",
    "    def __reset_stepsize__(self):\n",
    "        with torch.no_grad():\n",
    "            self.step_size.data = self.weight.abs().max() / self.half_lvls\n",
    "\n",
    "    def __reset_weight__(self):\n",
    "        with torch.no_grad():\n",
    "            self.weight.data = quantize(self.weight, self.step_size, self.half_lvls)\n",
    "        self.inf_with_weight = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37fcad76-3af7-4814-9f3f-115a0d6e6353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleA(nn.Module):\n",
    "    def __init__(self, nIn, nOut, stride):\n",
    "        super(DownsampleA, self).__init__()\n",
    "        assert stride == 2\n",
    "        self.avg = nn.AvgPool1d(kernel_size=1, stride=stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avg(x)\n",
    "        return torch.cat((x, x.mul(0)), 1)\n",
    "        \n",
    "class SEBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.conv_a = quan_Conv1d(inplanes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn_a = nn.BatchNorm1d(planes)\n",
    "        self.dropout_a = nn.Dropout(p=0.3)  # Dropout sau BatchNorm\n",
    "\n",
    "        self.conv_b = quan_Conv1d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn_b = nn.BatchNorm1d(planes)\n",
    "        self.dropout_b = nn.Dropout(p=0.3)  # Dropout sau BatchNorm\n",
    "\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        basicblock = self.conv_a(x)\n",
    "        basicblock = self.bn_a(basicblock)\n",
    "        basicblock = F.relu(basicblock, inplace=True)\n",
    "        basicblock = self.dropout_a(basicblock)  # Áp dụng dropout\n",
    "\n",
    "        basicblock = self.conv_b(basicblock)\n",
    "        basicblock = self.bn_b(basicblock)\n",
    "        basicblock = self.dropout_b(basicblock)  # Áp dụng dropout\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        return F.relu(residual + basicblock, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b7bf3-7bc7-4e4f-b34c-7b60196f150d",
   "metadata": {},
   "source": [
    "### Class CustomModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00cab76a-39cf-453d-b657-ca053aee8d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, input_size=39, hidden_sizes=[32, 64, 128, 256, 512], output_size=34):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.fc1 = quan_Conv1d(input_size, hidden_sizes[0], kernel_size=3, stride=1, padding=1)\n",
    "        self.bn_1 = nn.BatchNorm1d(hidden_sizes[0])\n",
    "\n",
    "        self.inplanes = 32\n",
    "        self.stage_1 = self._make_layer(SEBlock, 32, 16, 1)\n",
    "        self.stage_2 = self._make_layer(SEBlock, 64, 16, 2)\n",
    "        self.stage_3 = self._make_layer(SEBlock, 128, 16, 2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.classifier = CustomBlock(128 * SEBlock.expansion, output_size)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                n = m.kernel_size[0] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                #m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.kaiming_normal(m.weight)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        downsample = None\n",
    "        if stride == 2 or self.inplanes != planes * SEBlock.expansion:\n",
    "            downsample = DownsampleA(self.inplanes, planes * SEBlock.expansion, stride) if stride == 2 else None\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride=1, downsample=downsample))\n",
    "        self.inplanes = planes * SEBlock.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.bn_1(x), inplace=True)\n",
    "        \n",
    "        x = self.stage_1(x)\n",
    "        x = self.stage_2(x)\n",
    "        x = self.stage_3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4518cc2-57d4-474d-b206-68dfd5baa981",
   "metadata": {},
   "source": [
    "### Class CustomModel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aa14999-e6e2-4a3b-8eb1-7032515747b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel2(nn.Module):\n",
    "    def __init__(self, input_size=39, hidden_sizes=[32, 64, 128, 100], output_size=34):\n",
    "        super(CustomModel2, self).__init__()\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Conv1d(input_size, hidden_sizes[0], kernel_size=3, stride=2, padding=1)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        self.stage_1 = nn.Conv1d(hidden_sizes[0], hidden_sizes[1], kernel_size=3, stride=2, padding=1)\n",
    "        self.stage_2 = nn.Conv1d(hidden_sizes[1], hidden_sizes[2], kernel_size=3, stride=2, padding=1)\n",
    "        self.stage_3 = nn.Conv1d(hidden_sizes[2], hidden_sizes[3], kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Global Pooling\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = CustomBlock(hidden_sizes[-1], output_size, apply_softmax=True)\n",
    "        nn.Dropout(0.15)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass through layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(self.pool(x))\n",
    "\n",
    "        x = self.stage_1(x)\n",
    "        x = self.activation(self.pool(x))\n",
    "\n",
    "        x = self.stage_2(x)\n",
    "        x = self.activation(self.pool(x))\n",
    "\n",
    "        x = self.stage_3(x)\n",
    "        x = self.activation(self.pool(x))\n",
    "\n",
    "        # Global Pooling\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37be8524-9419-4c78-a136-c665a10da763",
   "metadata": {},
   "source": [
    "### Init dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c6d2715-cc0b-4a89-86b6-7b7859d97691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:16: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\m'\n",
      "/tmp/ipykernel_1724256/2434298026.py:16: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  self.resume = 'save\\model_best.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.arch = 'CustomModel'\n",
    "        self.data_path = '../../dataset/'\n",
    "        self.dataset = 'inid'\n",
    "        self.save_path = './save/attack_random'\n",
    "        self.epochs = 20\n",
    "        self.optimizer = 'SGD'\n",
    "        self.test_batch_size = 32\n",
    "        self.learning_rate = 0.001\n",
    "        self.momentum = 0.9\n",
    "        self.decay = 1e-4\n",
    "        self.schedule = [80, 120]\n",
    "        self.gammas = [0.1, 0.1]\n",
    "        self.print_freq = 100\n",
    "        self.resume = 'save\\model_best.pth.tar'\n",
    "        self.start_epoch = 0\n",
    "        self.enable_bfa = False\n",
    "        self.evaluate = False\n",
    "        self.ngpu = 1\n",
    "        self.gpu_id = 0\n",
    "        self.workers = 4\n",
    "        self.manualSeed = None\n",
    "        self.quan_bitwidth = 16\n",
    "        self.reset_weight = False\n",
    "        self.bfa = True\n",
    "        self.attack_sample_size = 128\n",
    "        self.n_iter = 25\n",
    "        self.k_top = None\n",
    "        self.random_bfa = True\n",
    "        self.progressive_bit_search= True\n",
    "        self.random_flip = True\n",
    "        self.clustering = False\n",
    "        self.lambda_coeff = 1e-3\n",
    "        self.use_cuda = True  \n",
    "\n",
    "args = Args()\n",
    "args.use_cuda = torch.cuda.is_available() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "896db0e2-2ae5-4eeb-a5be-9513eb168b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Save path: ./save/attack_random\n",
      "State: {'arch': 'CustomModel', 'attack_sample_size': 128, 'bfa': True, 'clustering': False, 'data_path': '../../dataset/', 'dataset': 'inid', 'decay': 0.0001, 'enable_bfa': False, 'epochs': 20, 'evaluate': False, 'gammas': [0.1, 0.1], 'gpu_id': 0, 'k_top': None, 'lambda_coeff': 0.001, 'learning_rate': 0.001, 'manualSeed': None, 'momentum': 0.9, 'n_iter': 25, 'ngpu': 1, 'optimizer': 'SGD', 'print_freq': 100, 'progressive_bit_search': True, 'quan_bitwidth': 16, 'random_bfa': True, 'random_flip': True, 'reset_weight': False, 'resume': 'save\\\\model_best.pth.tar', 'save_path': './save/attack_random', 'schedule': [80, 120], 'start_epoch': 0, 'test_batch_size': 32, 'use_cuda': True, 'workers': 4}\n",
      "Random Seed: None\n",
      "Python version: 3.12.6 | packaged by conda-forge | (main, Sep 22 2024, 14:16:49) [GCC 13.3.0]\n",
      "Torch version: 2.8.0+cu129\n",
      "CUDNN version: 91002\n"
     ]
    }
   ],
   "source": [
    "# Thiết lập cấu hình logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Init logger\n",
    "if not os.path.isdir(args.save_path):\n",
    "    os.makedirs(args.save_path)\n",
    "\n",
    "# Tạo tệp log\n",
    "log_file_path = os.path.join(args.save_path, 'log_seed_{}.txt'.format(args.manualSeed))\n",
    "file_handler = logging.FileHandler(log_file_path)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Định dạng cho tệp log\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# Thêm file handler vào logger\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Ghi log vào console và tệp\n",
    "logger.info('Save path: {}'.format(args.save_path))\n",
    "state = {k: getattr(args, k) for k in dir(args) if not k.startswith('__')}\n",
    "logger.info('State: {}'.format(state))\n",
    "logger.info(\"Random Seed: {}\".format(args.manualSeed))\n",
    "logger.info(\"Python version: {}\".format(sys.version.replace('\\n', ' ')))\n",
    "logger.info(\"Torch version: {}\".format(torch.__version__))\n",
    "logger.info(\"CUDNN version: {}\".format(torch.backends.cudnn.version()))\n",
    "\n",
    "# Init the tensorboard path and writer\n",
    "tb_path = os.path.join(args.save_path, 'tb_log', 'run_' + str(args.manualSeed))\n",
    "writer = SummaryWriter(tb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcada582-5dd5-4a18-82bd-bedbe8d01b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inid dataset import sucsess!\n"
     ]
    }
   ],
   "source": [
    "# Init dataset\n",
    "if not os.path.isdir(args.data_path):\n",
    "    os.makedirs(args.data_path)\n",
    "\n",
    "if args.dataset == 'inid':\n",
    "    print(\"Inid dataset import sucsess!\")\n",
    "else:\n",
    "    assert False, \"Unknow dataset : {}\".format(args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b1c44c7-8223-4bb5-92cf-416ec52171c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec2022se05/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "=> creating model 'CustomModel'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of y_train: torch.Size([435954])\n",
      "Data type of y_test: torch.Size([108989])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header_Length</th>\n",
       "      <th>Protocol Type</th>\n",
       "      <th>Time_To_Live</th>\n",
       "      <th>Rate</th>\n",
       "      <th>fin_flag_number</th>\n",
       "      <th>syn_flag_number</th>\n",
       "      <th>rst_flag_number</th>\n",
       "      <th>psh_flag_number</th>\n",
       "      <th>ack_flag_number</th>\n",
       "      <th>ece_flag_number</th>\n",
       "      <th>...</th>\n",
       "      <th>LLC</th>\n",
       "      <th>Tot sum</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>AVG</th>\n",
       "      <th>Std</th>\n",
       "      <th>Tot size</th>\n",
       "      <th>IAT</th>\n",
       "      <th>Number</th>\n",
       "      <th>Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.672433</td>\n",
       "      <td>-0.384137</td>\n",
       "      <td>-0.241073</td>\n",
       "      <td>0.033427</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>6421</td>\n",
       "      <td>60</td>\n",
       "      <td>481</td>\n",
       "      <td>64.21</td>\n",
       "      <td>42.100000</td>\n",
       "      <td>64.21</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>100</td>\n",
       "      <td>1772.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.615759</td>\n",
       "      <td>3.780463</td>\n",
       "      <td>-0.201938</td>\n",
       "      <td>-0.679955</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>57320</td>\n",
       "      <td>98</td>\n",
       "      <td>578</td>\n",
       "      <td>573.20</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>573.20</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>100</td>\n",
       "      <td>2304.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.705996</td>\n",
       "      <td>0.733195</td>\n",
       "      <td>-0.085147</td>\n",
       "      <td>-0.166566</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6010</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>60.10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.10</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.727570</td>\n",
       "      <td>-0.384137</td>\n",
       "      <td>2.641403</td>\n",
       "      <td>-0.790616</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2223</td>\n",
       "      <td>54</td>\n",
       "      <td>1500</td>\n",
       "      <td>222.30</td>\n",
       "      <td>451.596686</td>\n",
       "      <td>222.30</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>10</td>\n",
       "      <td>203939.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.579001</td>\n",
       "      <td>-0.892015</td>\n",
       "      <td>-0.204384</td>\n",
       "      <td>0.131488</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6006</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>60.06</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>60.06</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>100</td>\n",
       "      <td>0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712305</th>\n",
       "      <td>-1.606570</td>\n",
       "      <td>3.780463</td>\n",
       "      <td>0.148435</td>\n",
       "      <td>-0.699755</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>56436</td>\n",
       "      <td>70</td>\n",
       "      <td>578</td>\n",
       "      <td>564.36</td>\n",
       "      <td>79.049086</td>\n",
       "      <td>564.36</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>100</td>\n",
       "      <td>6248.757980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712306</th>\n",
       "      <td>0.681623</td>\n",
       "      <td>-0.384137</td>\n",
       "      <td>-0.201938</td>\n",
       "      <td>0.267584</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6000</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712307</th>\n",
       "      <td>-0.696806</td>\n",
       "      <td>0.733195</td>\n",
       "      <td>-0.201938</td>\n",
       "      <td>0.777507</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6000</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712308</th>\n",
       "      <td>0.681623</td>\n",
       "      <td>-0.384137</td>\n",
       "      <td>0.031644</td>\n",
       "      <td>-0.461580</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6061</td>\n",
       "      <td>60</td>\n",
       "      <td>121</td>\n",
       "      <td>60.61</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>60.61</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>100</td>\n",
       "      <td>37.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712309</th>\n",
       "      <td>0.681623</td>\n",
       "      <td>-0.384137</td>\n",
       "      <td>-0.201938</td>\n",
       "      <td>-0.049287</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6000</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>544943 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Header_Length  Protocol Type  Time_To_Live      Rate  fin_flag_number  \\\n",
       "0            0.672433      -0.384137     -0.241073  0.033427             0.00   \n",
       "1           -1.615759       3.780463     -0.201938 -0.679955             0.00   \n",
       "2           -0.705996       0.733195     -0.085147 -0.166566             0.00   \n",
       "3            0.727570      -0.384137      2.641403 -0.790616             0.10   \n",
       "4           -1.579001      -0.892015     -0.204384  0.131488             0.00   \n",
       "...               ...            ...           ...       ...              ...   \n",
       "712305      -1.606570       3.780463      0.148435 -0.699755             0.00   \n",
       "712306       0.681623      -0.384137     -0.201938  0.267584             0.00   \n",
       "712307      -0.696806       0.733195     -0.201938  0.777507             0.00   \n",
       "712308       0.681623      -0.384137      0.031644 -0.461580             0.98   \n",
       "712309       0.681623      -0.384137     -0.201938 -0.049287             0.00   \n",
       "\n",
       "        syn_flag_number  rst_flag_number  psh_flag_number  ack_flag_number  \\\n",
       "0                   0.0             0.00             0.99             0.99   \n",
       "1                   0.0             0.00             0.00             0.00   \n",
       "2                   0.0             0.00             0.00             0.00   \n",
       "3                   0.0             0.30             0.20             0.40   \n",
       "4                   0.0             0.00             0.00             0.01   \n",
       "...                 ...              ...              ...              ...   \n",
       "712305              0.0             0.00             0.00             0.00   \n",
       "712306              1.0             0.00             0.00             0.00   \n",
       "712307              0.0             0.00             0.00             0.00   \n",
       "712308              0.0             0.98             0.01             0.02   \n",
       "712309              1.0             0.00             0.00             0.00   \n",
       "\n",
       "        ece_flag_number  ...   LLC  Tot sum  Min   Max     AVG         Std  \\\n",
       "0                   0.0  ...  0.99     6421   60   481   64.21   42.100000   \n",
       "1                   0.0  ...  1.00    57320   98   578  573.20   48.000000   \n",
       "2                   0.0  ...  1.00     6010   60    70   60.10    1.000000   \n",
       "3                   0.0  ...  0.90     2223   54  1500  222.30  451.596686   \n",
       "4                   0.0  ...  1.00     6006   60    66   60.06    0.600000   \n",
       "...                 ...  ...   ...      ...  ...   ...     ...         ...   \n",
       "712305              0.0  ...  1.00    56436   70   578  564.36   79.049086   \n",
       "712306              0.0  ...  1.00     6000   60    60   60.00    0.000000   \n",
       "712307              0.0  ...  1.00     6000   60    60   60.00    0.000000   \n",
       "712308              0.0  ...  1.00     6061   60   121   60.61    6.100000   \n",
       "712309              0.0  ...  1.00     6000   60    60   60.00    0.000000   \n",
       "\n",
       "        Tot size       IAT  Number       Variance  \n",
       "0          64.21  0.000039     100    1772.410000  \n",
       "1         573.20  0.000271     100    2304.000000  \n",
       "2          60.10  0.000057     100       1.000000  \n",
       "3         222.30  0.004766      10  203939.566667  \n",
       "4          60.06  0.000035     100       0.360000  \n",
       "...          ...       ...     ...            ...  \n",
       "712305    564.36  0.000325     100    6248.757980  \n",
       "712306     60.00  0.000034     100       0.000000  \n",
       "712307     60.00  0.000020     100       0.000000  \n",
       "712308     60.61  0.000102     100      37.210000  \n",
       "712309     60.00  0.000048     100       0.000000  \n",
       "\n",
       "[544943 rows x 39 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init dataset\n",
    "if args.dataset == 'inid':\n",
    "    data = pd.read_csv(\"../support/dataset/CICIoT2023/CIC_IoT_Dataset2023.csv\", skipinitialspace=True)\n",
    "    \n",
    "    # Remove duplicates and handle NaN values\n",
    "\n",
    "    data = data.drop_duplicates()\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data.fillna(0, inplace=True)\n",
    "    \n",
    "    # Separate labels and data\n",
    "    datalabel = data[['Label']]\n",
    "    data = data.drop(columns=['Label'])\n",
    "    \n",
    "    # Normalize numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    data[['Header_Length', 'Protocol Type', 'Time_To_Live', 'Rate']] = scaler.fit_transform(\n",
    "        data[['Header_Length', 'Protocol Type', 'Time_To_Live', 'Rate']]\n",
    "    )\n",
    "    \n",
    "    # Label Encoding\n",
    "    onc = LabelEncoder()\n",
    "    y = onc.fit_transform(datalabel['Label'].to_numpy().reshape(-1, 1))\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=100)\n",
    "    \n",
    "    # Normalize X_train and X_test\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Convert y_train and y_test to Tensor\n",
    "    y_train = torch.LongTensor(y_train)\n",
    "    y_test = torch.LongTensor(y_test)\n",
    "    \n",
    "    # Check data types\n",
    "    print(\"Data type of y_train:\", y_train.shape)\n",
    "    print(\"Data type of y_test:\", y_test.shape)\n",
    "    \n",
    "    # Create DataLoader for training set\n",
    "    train_loader = DataLoader(\n",
    "        torch.utils.data.TensorDataset(\n",
    "            torch.FloatTensor(X_train),\n",
    "            y_train\n",
    "        ),\n",
    "        batch_size=256,\n",
    "        num_workers=5,\n",
    "        shuffle=True,\n",
    "        pin_memory=True \n",
    "    )\n",
    "    \n",
    "    # Create DataLoader for testing set\n",
    "    test_loader = DataLoader(\n",
    "        torch.utils.data.TensorDataset(\n",
    "            torch.FloatTensor(X_test),\n",
    "            y_test\n",
    "        ),\n",
    "        batch_size=256,\n",
    "        num_workers=5,\n",
    "        shuffle=False,\n",
    "        pin_memory=True \n",
    "    )\n",
    "else:\n",
    "    # Code for other datasets\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=args.attack_sample_size,\n",
    "        shuffle=True,\n",
    "        num_workers=args.workers,\n",
    "        pin_memory=True \n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_data,\n",
    "        batch_size=args.test_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=args.workers,\n",
    "        pin_memory=True \n",
    "    )\n",
    "\n",
    "logger.info(\"=> creating model '{}'\".format(args.arch))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba26c0f8-c31c-4391-b077-66165d0b8f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc_score(preds, targets):\n",
    "    preds = preds.cpu().numpy()\n",
    "    targets = targets.cpu().numpy()\n",
    "    return matthews_corrcoef(targets, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99229d0e-0d79-4b51-beb2-c70f5f5c53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc2(outputs_label, outputs_cat, y_label_batch, y_cat_batch):\n",
    "    \"\"\"Compute MCC for each output of the model (label, category).\"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Ensure target has at least one dimension\n",
    "        if y_label_batch.dim() == 0:\n",
    "            y_label_batch = y_label_batch.unsqueeze(0)\n",
    "        if y_cat_batch.dim() == 0:\n",
    "            y_cat_batch = y_cat_batch.unsqueeze(0)\n",
    "\n",
    "        # Get the predicted classes (top-1 prediction) for each output\n",
    "        _, pred_label = outputs_label.topk(1, 1, True, True)\n",
    "        _, pred_cat = outputs_cat.topk(1, 1, True, True)\n",
    "\n",
    "        # Compute MCC for each output type\n",
    "        mcc_label = mcc_score(pred_label.view(-1), y_label_batch)\n",
    "        mcc_cat = mcc_score(pred_cat.view(-1), y_cat_batch)\n",
    "\n",
    "        return mcc_label, mcc_cat\n",
    "\n",
    "\n",
    "def mcc(output, target):\n",
    "    \"\"\"Compute the Matthews Correlation Coefficient (MCC) for the given output and target.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Ensure target has at least one dimension\n",
    "        if target.dim() == 0:\n",
    "            target = target.unsqueeze(0)\n",
    "\n",
    "        # Get the predicted classes (top-1 prediction)\n",
    "        _, pred = output.topk(1, 1, True, True)\n",
    "        return mcc_score(pred.view(-1), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41d98736-bb0a-4d10-9422-11caa334f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7f291e-ad43-4770-9e9a-0a0a07850136",
   "metadata": {},
   "source": [
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e39667a-f0ba-49cc-bc17-9fe62aaa29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    mcc_meter = AverageMeter()  # Track MCC instead of accuracy\n",
    "\n",
    "    # Switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # Measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if args.use_cuda:\n",
    "            input = input.cuda(non_blocking=True)\n",
    "            target = target.cuda(non_blocking=True)\n",
    "            \n",
    "        input = input.view(input.size(0), 39, -1)  # Reshape input\n",
    "        \n",
    "        # Compute output and loss\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        if args.clustering:\n",
    "            loss += clustering_loss(model, args.lambda_coeff)\n",
    "\n",
    "        # Compute MCC and record loss\n",
    "        mcc_value = mcc(output.data, target)  # MCC calculation instead of topk accuracy\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        mcc_meter.update(mcc_value, input.size(0))\n",
    "\n",
    "        # Compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "    return mcc_meter.avg, losses.avg\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, summary_output=True):\n",
    "    losses = AverageMeter()\n",
    "    mcc_meter = AverageMeter()\n",
    "    acc_meter = AverageMeter()\n",
    "    tpr_meter = AverageMeter()\n",
    "    f1_meter = AverageMeter()\n",
    "\n",
    "    # Chuyển model sang chế độ đánh giá\n",
    "    model.eval()\n",
    "    output_summary = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(test_loader):\n",
    "            if input.size(1) == 39 and input.dim() == 2:  # Kiểm tra nếu thiếu chiều thứ 3\n",
    "                input = input.unsqueeze(-1)\n",
    "\n",
    "            if torch.cuda.is_available() and args.use_cuda:\n",
    "                target = target.cuda(non_blocking=True)\n",
    "                input = input.cuda(non_blocking=True)\n",
    "\n",
    "            # Tính toán output và loss\n",
    "            output = model(input)\n",
    "            pred = torch.argmax(output, dim=1)  # Chọn nhãn dự đoán có xác suất cao nhất\n",
    "            loss = criterion(output, target)\n",
    "            losses.update(loss.item(), input.size(0))  # Cập nhật losses\n",
    "\n",
    "            # Chuyển sang numpy để tính toán các chỉ số\n",
    "            pred_np = pred.cpu().numpy()\n",
    "            target_np = target.cpu().numpy()\n",
    "\n",
    "            if summary_output:\n",
    "                tmp_list = output.max(1, keepdim=True)[1].flatten().cpu().numpy() # get the index of the max log-probability\n",
    "                output_summary.append(tmp_list)\n",
    "\n",
    "            # Tính các chỉ số đánh giá\n",
    "            mcc_value = matthews_corrcoef(target_np, pred_np)\n",
    "            acc_value = accuracy_score(target_np, pred_np)\n",
    "            tpr_value = recall_score(target_np, pred_np, average='macro')  # Macro recall ~ TPR\n",
    "            f1_value = f1_score(target_np, pred_np, average='macro')\n",
    "\n",
    "            # Cập nhật giá trị trung bình\n",
    "            mcc_meter.update(mcc_value, input.size(0))\n",
    "            acc_meter.update(acc_value, input.size(0))\n",
    "            tpr_meter.update(tpr_value, input.size(0))\n",
    "            f1_meter.update(f1_value, input.size(0))\n",
    "\n",
    "    return mcc_meter.avg, acc_meter.avg, tpr_meter.avg, f1_meter.avg, losses.avg, output_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1687046-4b16-4dce-9495-484ece92b6b1",
   "metadata": {},
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8d35b5b-6c57-4d4e-8747-560eaa878af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, recall_score, f1_score\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "# Tắt cảnh báo UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "def validate_score(model, test_loader):\n",
    "    losses = AverageMeter()\n",
    "    mcc_meter = AverageMeter()\n",
    "    acc_meter = AverageMeter()\n",
    "    tpr_meter = AverageMeter()\n",
    "    f1_meter = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(test_loader):\n",
    "            if input.size(1) == 39 and input.dim() == 2:  # Kiểm tra nếu thiếu chiều thứ 3\n",
    "                input = input.unsqueeze(-1)\n",
    "\n",
    "            if torch.cuda.is_available() and args.use_cuda:\n",
    "                target = target.cuda(non_blocking=True)\n",
    "                input = input.cuda(non_blocking=True)\n",
    "\n",
    "            # Tính toán output và loss\n",
    "            output = model(input)\n",
    "            pred = torch.argmax(output, dim=1)  # Chọn nhãn dự đoán có xác suất cao nhất\n",
    "\n",
    "            # Chuyển sang numpy để tính toán các chỉ số\n",
    "            pred_np = pred.cpu().numpy()\n",
    "            target_np = target.cpu().numpy()\n",
    "\n",
    "            # Tính các chỉ số đánh giá\n",
    "            mcc_value = matthews_corrcoef(target_np, pred_np)\n",
    "            acc_value = accuracy_score(target_np, pred_np)\n",
    "            tpr_value = recall_score(target_np, pred_np, average='macro')  # Macro recall ~ TPR\n",
    "            f1_value = f1_score(target_np, pred_np, average='macro')\n",
    "\n",
    "            # Cập nhật giá trị trung bình\n",
    "            mcc_meter.update(mcc_value, input.size(0))\n",
    "            acc_meter.update(acc_value, input.size(0))\n",
    "            tpr_meter.update(tpr_value, input.size(0))\n",
    "            f1_meter.update(f1_value, input.size(0))\n",
    "\n",
    "    return {\n",
    "        \"MCC\": mcc_meter.avg,\n",
    "        \"Accuracy\": acc_meter.avg,\n",
    "        \"TPR\": tpr_meter.avg,\n",
    "        \"F1 Score\": f1_meter.avg\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db928785-c739-49a0-af06-9b3adb6fc504",
   "metadata": {},
   "source": [
    "### class BFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74582bcb-fbb1-4843-b49d-8b886e216d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BFA(object):\n",
    "    def __init__(self, criterion, model, k_top=10):\n",
    "        self.criterion = criterion\n",
    "        self.loss_dict = {}\n",
    "        self.bit_counter = 0\n",
    "        self.k_top = k_top\n",
    "        self.n_bits2flip = 0\n",
    "        self.loss = 0\n",
    "        self.num_bit_flipped = 0\n",
    "        \n",
    "        # Attributes for random attack\n",
    "        self.module_list = []\n",
    "\n",
    "        for name, m in model.named_modules():\n",
    "            if isinstance(m, (quan_Conv1d, quan_Linear, CustomBlock)):\n",
    "                self.module_list.append(name)\n",
    "\n",
    "    def flip_bit(self, m):\n",
    "        '''\n",
    "        the data type of input param is 32-bit floating, then return the data should\n",
    "        be in the same data_type.\n",
    "        '''\n",
    "        if self.k_top is None:\n",
    "            k_top = m.weight.detach().flatten().__len__()\n",
    "        else: \n",
    "            k_top = self.k_top\n",
    "        # 1. flatten the gradient tensor to perform topk\n",
    "        w_grad_topk, w_idx_topk = m.weight.grad.detach().abs().view(-1).topk(k_top)\n",
    "        # update the b_grad to its signed representation\n",
    "        w_grad_topk = m.weight.grad.detach().view(-1)[w_idx_topk]\n",
    "\n",
    "        # 2. create the b_grad matrix in shape of [N_bits, k_top]\n",
    "        b_grad_topk = w_grad_topk * m.b_w.data\n",
    "\n",
    "        # 3. generate the gradient mask to zero-out the bit-gradient\n",
    "        # which can not be flipped\n",
    "        b_grad_topk_sign = (b_grad_topk.sign() +\n",
    "                            1) * 0.5  # zero -> negative, one -> positive\n",
    "        # convert to twos complement into unsigned integer\n",
    "        w_bin = int2bin(m.weight.detach().view(-1), m.N_bits).short()\n",
    "        w_bin_topk = w_bin[w_idx_topk]  # get the weights whose grads are topk\n",
    "        \n",
    "        # generate two's complement bit-map\n",
    "        b_bin_topk = (w_bin_topk.repeat(m.N_bits, 1) & m.b_w.abs().repeat(1, k_top).short()) \\\n",
    "           // m.b_w.abs().repeat(1, k_top).short()\n",
    "\n",
    "        grad_mask = b_bin_topk ^ b_grad_topk_sign.short()\n",
    "\n",
    "        # 4. apply the gradient mask upon ```b_grad_topk``` and in-place update it\n",
    "        b_grad_topk *= grad_mask.float()\n",
    "\n",
    "        # 5. identify the several maximum of absolute bit gradient and return the index, the number of bits to flip is self.n_bits2flip\n",
    "\n",
    "        grad_max = b_grad_topk.abs().max()\n",
    "        num_elements = b_grad_topk.nelement()  # Get the total number of elements\n",
    "        k = min(self.n_bits2flip, num_elements)  # Clamp the value of k\n",
    "    \n",
    "        _, b_grad_max_idx = b_grad_topk.abs().view(-1).topk(k)  # Use clamped k\n",
    "        bit2flip = b_grad_topk.clone().view(-1).zero_()\n",
    "\n",
    "        if grad_max.item() != 0:  # ensure the max grad is not zero\n",
    "            bit2flip[b_grad_max_idx] = 1\n",
    "            bit2flip = bit2flip.view(b_grad_topk.size())\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # 6. Based on the identified bit indexed by ```bit2flip```, generate another\n",
    "        # mask, then perform the bitwise xor operation to realize the bit-flip.\n",
    "        bit2flip = bit2flip.reshape(m.b_w.abs().shape[0], -1)  # Định hình lại\n",
    "\n",
    "        w_bin_topk_flipped = (bit2flip.short() * m.b_w.abs().short()).sum(0, dtype=torch.int16) \\\n",
    "            ^ w_bin_topk\n",
    "\n",
    "        # 7. update the weight in the original weight tensor\n",
    "        w_bin[w_idx_topk] = w_bin_topk_flipped  # in-place change\n",
    "        param_flipped = bin2int(w_bin,\n",
    "                                m.N_bits).view(m.weight.data.size()).float()\n",
    "\n",
    "        return param_flipped\n",
    "\n",
    "    def progressive_bit_search(self, model, data, target, test_loader):\n",
    "        ''' \n",
    "        Given the model, based on the current data and target, go through\n",
    "        all the layers and identify the bits to be flipped. \n",
    "        '''\n",
    "        model.eval()\n",
    "        output = model(data)\n",
    "        self.loss = self.criterion(output, target)\n",
    "    \n",
    "        # Zero out the grads first, then get the grads\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, (quan_Conv1d, quan_Linear, CustomBlock)):\n",
    "                if m.weight.grad is not None:\n",
    "                    m.weight.grad.data.zero_()\n",
    "    \n",
    "        self.loss.backward()\n",
    "        self.loss_max = self.loss.item()\n",
    "        attack_log = []\n",
    "        max_loss_module = None\n",
    "    \n",
    "        # 3. Flip bits until no further loss degradation is observed\n",
    "        while self.loss_max <= self.loss.item():\n",
    "            self.n_bits2flip += 1\n",
    "            self.loss_dict = {}\n",
    "    \n",
    "            for name, module in model.named_modules():\n",
    "                if isinstance(module, CustomBlock) or isinstance(module, quan_Conv1d):\n",
    "                    clean_weight = module.weight.data.detach()\n",
    "                    attack_weight = self.flip_bit(module)\n",
    "                    self.num_bit_flipped += 1\n",
    "    \n",
    "                    module.weight.data = attack_weight\n",
    "                    output = model(data)\n",
    "    \n",
    "                    self.loss_dict[name] = self.criterion(output, target).item()\n",
    "                    module.weight.data = clean_weight\n",
    "    \n",
    "            # Check if loss_dict is not empty\n",
    "            if not self.loss_dict:\n",
    "                break\n",
    "    \n",
    "            max_loss_module = max(self.loss_dict.items(), key=lambda item: item[1])[0]\n",
    "            self.loss_max = self.loss_dict[max_loss_module]\n",
    "    \n",
    "            if self.n_bits2flip == 100:\n",
    "                break\n",
    "    \n",
    "        # Check if max_loss_module was never assigned\n",
    "        if max_loss_module is None:\n",
    "            attack_last_status = [self.bit_counter, \"No module attacked\", \"No attack\", \"No attack\"]\n",
    "            return [], validate_score(model, test_loader), self.bit_counter, attack_last_status\n",
    "    \n",
    "        weight_prior = None\n",
    "        weight_post = None\n",
    "    \n",
    "        # If loss_max does lead to degradation, change that layer's weight\n",
    "        for module_idx, (name, module) in enumerate(model.named_modules()):\n",
    "            if name == max_loss_module:\n",
    "                attack_weight = self.flip_bit(module)\n",
    "                self.num_bit_flipped += 1\n",
    "    \n",
    "                ###########################################################\n",
    "                ## Attack profiling\n",
    "                ##########################################################\n",
    "                \n",
    "                weight_mismatch = attack_weight - module.weight.detach()\n",
    "                attack_weight_idx = torch.nonzero(weight_mismatch)\n",
    "                print('attacked module:', max_loss_module)\n",
    "                \n",
    "                attack_log = []\n",
    "                for i in range(attack_weight_idx.size(0)):\n",
    "                    weight_idx = attack_weight_idx[i, :].cpu().numpy()\n",
    "                    weight_prior = module.weight.detach()[tuple(weight_idx)].item()\n",
    "                    weight_post = attack_weight[tuple(weight_idx)].item()\n",
    "                \n",
    "                    tmp_list = [module_idx, self.bit_counter + (i + 1), max_loss_module,\n",
    "                                weight_idx, weight_prior, weight_post]\n",
    "                    attack_log.append(tmp_list)\n",
    "    \n",
    "                module.weight.data = attack_weight\n",
    "    \n",
    "        self.bit_counter += self.n_bits2flip\n",
    "        self.n_bits2flip = 0\n",
    "    \n",
    "        if weight_prior is None or weight_post is None:\n",
    "            attack_last_status = [self.bit_counter, max_loss_module, \"No attack\", \"No attack\"]\n",
    "        else:\n",
    "            attack_last_status = [self.bit_counter, max_loss_module, weight_prior, weight_post]\n",
    "        \n",
    "        return attack_log, validate_score(model, test_loader), self.bit_counter, attack_last_status\n",
    "\n",
    "    def random_flip_one_bit(self, model, test_loader):\n",
    "        \"\"\"\n",
    "        Randomly flip one bit in the weight of a chosen module.\n",
    "        \"\"\"\n",
    "        weight_prior = None\n",
    "        weight_post = None\n",
    "        \n",
    "        chosen_module = random.choice(self.module_list)\n",
    "        for name, m in model.named_modules():\n",
    "            if name == chosen_module:\n",
    "                flatten_weight = m.weight.detach().view(-1)\n",
    "                chosen_idx = random.choice(range(flatten_weight.numel()))\n",
    "                bin_w = int2bin(flatten_weight[chosen_idx], m.N_bits).short()\n",
    "                bit_idx = random.choice(range(m.N_bits))\n",
    "                mask = (bin_w.clone().zero_() + 1) * (2 ** bit_idx)\n",
    "                bin_w = bin_w ^ mask\n",
    "                int_w = bin2int(bin_w, m.N_bits).float()\n",
    "\n",
    "                ##############################################\n",
    "                ###   attack profiling\n",
    "                ###############################################\n",
    "                \n",
    "                weight_mismatch = flatten_weight[chosen_idx] - int_w\n",
    "                attack_weight_idx = chosen_idx\n",
    "\n",
    "                print('attacked module:', chosen_module)\n",
    "                \n",
    "                attack_log = []\n",
    "                weight_idx = chosen_idx\n",
    "                weight_prior = flatten_weight[chosen_idx]\n",
    "                weight_post = int_w\n",
    "\n",
    "                print('attacked weight index:', weight_idx)\n",
    "                print('weight before attack:', weight_prior)\n",
    "                print('weight after attack:', weight_post)\n",
    "\n",
    "                tmp_list = [\"module_idx\", self.bit_counter + 1, \"loss\",\n",
    "                            weight_idx, weight_prior, weight_post]\n",
    "                attack_log.append(tmp_list)                            \n",
    "\n",
    "                self.bit_counter += 1\n",
    "                flatten_weight[chosen_idx] = int_w\n",
    "                m.weight.data = flatten_weight.view(m.weight.data.size())\n",
    "                \n",
    "        if weight_prior is None or weight_post is None:\n",
    "            attack_last_status = [self.bit_counter, chosen_module, \"No attack\", \"No attack\"]\n",
    "        else:\n",
    "            attack_last_status = [self.bit_counter, chosen_module, weight_prior, weight_post]\n",
    "\n",
    "        return attack_log, validate_score(model, test_loader), self.bit_counter, attack_last_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f84e2d5-5b3e-44c2-ad91-bb2db1f4123b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using SGD as optimizer\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = CustomModel().to(device)\n",
    "\n",
    "if args.use_cuda:\n",
    "    if args.ngpu > 1:\n",
    "        net = torch.nn.DataParallel(net, device_ids=list(range(args.ngpu)))\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.001, weight_decay=0.01)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# separate the parameters thus param groups can be updated by different optimizer\n",
    "all_param = [\n",
    "    param for name, param in net.named_parameters()\n",
    "    if not 'step_size' in name\n",
    "]\n",
    "\n",
    "step_param = [\n",
    "    param for name, param in net.named_parameters() if 'step_size' in name \n",
    "]\n",
    "\n",
    "if args.optimizer == \"SGD\":\n",
    "    print(\"using SGD as optimizer\")\n",
    "    optimizer = torch.optim.SGD(all_param,\n",
    "                                lr=0.01,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=0.0001,\n",
    "                                nesterov=True)\n",
    "\n",
    "elif args.optimizer == \"Adam\":\n",
    "    print(\"using Adam as optimizer\")\n",
    "    optimizer = torch.optim.Adam(filter(lambda param: param.requires_grad,\n",
    "                                        all_param),\n",
    "                                 lr=0.001,\n",
    "                                 #momentum=0.9,\n",
    "                                 weight_decay=0.001)\n",
    "\n",
    "\n",
    "elif args.optimizer == \"RMSprop\":\n",
    "    print(\"using RMSprop as optimizer\")\n",
    "    optimizer = torch.optim.RMSprop(\n",
    "        filter(lambda param: param.requires_grad, net.parameters()),\n",
    "        lr=0.01,\n",
    "        alpha=0.99,\n",
    "        eps=1e-08,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd90b235-b1f9-4fca-8436-8b556b04e691",
   "metadata": {},
   "source": [
    "## BFA Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24700838-e7ee-4af6-8d1c-368edf0b351e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found at 'save\\model_best.pth.tar'\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if args.use_cuda:\n",
    "    net.cuda()\n",
    "    criterion.cuda()\n",
    "\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        if not args.fine_tune:\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            recorder = checkpoint['recorder']\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "        state_tmp = net.state_dict()\n",
    "        if 'state_dict' in checkpoint.keys():\n",
    "            state_tmp.update(checkpoint['state_dict'])\n",
    "        else:\n",
    "            state_tmp.update(checkpoint)\n",
    "\n",
    "        net.load_state_dict(state_tmp, strict=False)\n",
    "    else:\n",
    "        print(\"No checkpoint found at '{}'\".format(args.resume))\n",
    "else:\n",
    "    print(\"Do not use any checkpoint for {} model\".format(args.arch))\n",
    "\n",
    "\n",
    "# Configure the quantization bit-width\n",
    "if args.quan_bitwidth is not None:\n",
    "    change_quan_bitwidth(net, args.quan_bitwidth)\n",
    "\n",
    "# Update the step_size once the model is loaded. This is used for quantization.\n",
    "for m in net.modules():\n",
    "    if isinstance(m, quan_Conv1d) or isinstance(m, quan_Linear) or isinstance(m, CustomBlock) or m.__class__.__name__ == \"CustomBlock\" or m.__class__.__name__ == \"quan_Conv1d\":\n",
    "        m.__reset_stepsize__()\n",
    "\n",
    "# Block for weight reset\n",
    "if args.reset_weight:\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, quan_Conv1d) or isinstance(m, quan_Linear) or isinstance(m, CustomBlock):\n",
    "            m.__reset_weight__()\n",
    "\n",
    "attacker = BFA(criterion, net, args.k_top)  # Khởi tạo đối tượng tấn công\n",
    "net_clean = copy.deepcopy(net)\n",
    "    # weight_conversion(net)\n",
    "\n",
    "if args.enable_bfa:\n",
    "    perform_attack(attacker, net, net_clean, train_loader, test_loader,\n",
    "                   args.n_iter, writer, csv_save_path=args.save_path,\n",
    "                   random_attack=args.random_bfa)\n",
    "\n",
    "if args.evaluate:\n",
    "    print(\"Evaluate mode\")\n",
    "    _, _, _, _, _, _, output_summary = validate(test_loader, net, criterion, summary_output=True)\n",
    "    pd.DataFrame(output_summary).to_csv(os.path.join(args.save_path, 'output_summary_{}.csv'.format(args.arch)),\n",
    "                                        header=['top-1 output'], index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bede100-21b0-4bf2-9614-b17a15142bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, gammas, schedule):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.learning_rate\n",
    "    mu = args.momentum\n",
    "\n",
    "    if args.optimizer != \"YF\":\n",
    "        assert len(gammas) == len(\n",
    "            schedule), \"length of gammas and schedule should be equal\"\n",
    "        for (gamma, step) in zip(gammas, schedule):\n",
    "            if (epoch >= step):\n",
    "                lr = lr * gamma\n",
    "            else:\n",
    "                break\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    elif args.optimizer == \"YF\":\n",
    "        lr = optimizer._lr\n",
    "        mu = optimizer._mu\n",
    "\n",
    "    return lr, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbd7e109-0734-4e16-8a5b-e19358496855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: 0 with seed: 8608\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "if args.ngpu == 1:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(\n",
    "        args.gpu_id)  # make only device #gpu_id visible, then\n",
    "\n",
    "args.use_cuda = args.ngpu > 0 and torch.cuda.is_available()  # check GPU\n",
    "\n",
    "# Give a random seed if no manual configuration\n",
    "if args.manualSeed is None:\n",
    "    args.manualSeed = random.randint(1, 10000)\n",
    "random.seed(args.manualSeed)\n",
    "torch.manual_seed(args.manualSeed)\n",
    "\n",
    "if args.use_cuda:\n",
    "    torch.cuda.manual_seed_all(args.manualSeed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if args.use_cuda:\n",
    "    print(f\"Using GPU: {args.gpu_id} with seed: {args.manualSeed}\")\n",
    "else:\n",
    "    print(f\"Using CPU with seed: {args.manualSeed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a48cb46-c3f3-4b1c-a3e0-63b33685a7b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Train Loss: 1.0145, Train MCC: 0.5517\n",
      "Validation Loss: 0.6116, Validation MCC: 0.6701\n",
      "Epoch 2/20\n",
      "Train Loss: 0.6150, Train MCC: 0.6661\n",
      "Validation Loss: 0.5661, Validation MCC: 0.6964\n",
      "Epoch 3/20\n",
      "Train Loss: 0.5811, Train MCC: 0.6831\n",
      "Validation Loss: 0.5425, Validation MCC: 0.7050\n",
      "Epoch 4/20\n",
      "Train Loss: 0.5611, Train MCC: 0.6942\n",
      "Validation Loss: 0.5329, Validation MCC: 0.7116\n",
      "Epoch 5/20\n",
      "Train Loss: 0.5483, Train MCC: 0.7026\n",
      "Validation Loss: 0.5194, Validation MCC: 0.7252\n",
      "Epoch 6/20\n",
      "Train Loss: 0.5351, Train MCC: 0.7110\n",
      "Validation Loss: 0.5003, Validation MCC: 0.7357\n",
      "Epoch 7/20\n",
      "Train Loss: 0.5227, Train MCC: 0.7185\n",
      "Validation Loss: 0.4991, Validation MCC: 0.7359\n",
      "Epoch 8/20\n",
      "Train Loss: 0.5121, Train MCC: 0.7238\n",
      "Validation Loss: 0.4863, Validation MCC: 0.7384\n",
      "Epoch 9/20\n",
      "Train Loss: 0.5064, Train MCC: 0.7268\n",
      "Validation Loss: 0.5109, Validation MCC: 0.7296\n",
      "Epoch 10/20\n",
      "Train Loss: 0.5170, Train MCC: 0.7170\n",
      "Validation Loss: 0.5091, Validation MCC: 0.7212\n",
      "Epoch 11/20\n",
      "Train Loss: 0.5065, Train MCC: 0.7254\n",
      "Validation Loss: 0.4797, Validation MCC: 0.7420\n",
      "Epoch 12/20\n",
      "Train Loss: 0.4953, Train MCC: 0.7322\n",
      "Validation Loss: 0.4785, Validation MCC: 0.7424\n",
      "Epoch 13/20\n",
      "Train Loss: 0.4935, Train MCC: 0.7327\n",
      "Validation Loss: 0.5451, Validation MCC: 0.7245\n",
      "Epoch 14/20\n",
      "Train Loss: 0.4914, Train MCC: 0.7339\n",
      "Validation Loss: 0.4766, Validation MCC: 0.7436\n",
      "Epoch 15/20\n",
      "Train Loss: 0.4899, Train MCC: 0.7342\n",
      "Validation Loss: 0.4722, Validation MCC: 0.7444\n",
      "Epoch 16/20\n",
      "Train Loss: 0.4883, Train MCC: 0.7355\n",
      "Validation Loss: 0.4760, Validation MCC: 0.7424\n",
      "Epoch 17/20\n",
      "Train Loss: 0.4865, Train MCC: 0.7359\n",
      "Validation Loss: 0.4717, Validation MCC: 0.7436\n",
      "Epoch 18/20\n",
      "Train Loss: 0.4851, Train MCC: 0.7370\n",
      "Validation Loss: 0.4703, Validation MCC: 0.7459\n",
      "Epoch 19/20\n",
      "Train Loss: 0.4840, Train MCC: 0.7375\n",
      "Validation Loss: 0.4722, Validation MCC: 0.7459\n",
      "Epoch 20/20\n",
      "Train Loss: 0.4830, Train MCC: 0.7374\n",
      "Validation Loss: 0.4701, Validation MCC: 0.7461\n",
      "Best MCC during training: 0.7460963574832288\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CustomModel().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 10  # Số epoch để chờ trước khi dừng\n",
    "counter = 0\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "# Vòng lặp huấn luyện\n",
    "best_val_loss = float('inf')\n",
    "best_mcc = -1  # Khởi tạo MCC tốt nhất\n",
    "\n",
    "# Vòng lặp huấn luyện\n",
    "for epoch in range(num_epochs):\n",
    "    train_mcc, train_loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    val_mcc, val_acc, val_tpr, val_f1, val_loss, output_summary = validate(test_loader, model, criterion, summary_output=True)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_mcc = val_mcc  # Lưu MCC tốt nhất\n",
    "        counter = 0\n",
    "\n",
    "        save_dir = \"CustomModel\"\n",
    "        save_path = os.path.join(save_dir, \"best_model.pth\")\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train MCC: {train_mcc:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation MCC: {val_mcc:.4f}\")\n",
    "print(f\"Best MCC during training: {best_mcc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d48ac-3ec1-42da-a557-591fbb18f1e1",
   "metadata": {},
   "source": [
    "## Random Attack\n",
    "\n",
    "### import data_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfca572d-36ef-4fd7-86cb-aa4958463a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int2bin(input, num_bits):\n",
    "    '''\n",
    "    convert the signed integer value into unsigned integer (2's complement equivalently).\n",
    "    Note that, the conversion is different depends on number of bit used.\n",
    "    '''\n",
    "    output = input.clone()\n",
    "    if num_bits == 1: # when it is binary, the conversion is different\n",
    "        output = output/2 + .5\n",
    "    elif num_bits > 1:\n",
    "        output[input.lt(0)] = 2**num_bits + output[input.lt(0)]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def bin2int(input, num_bits):\n",
    "    '''\n",
    "    convert the unsigned integer (2's complement equivantly) back to the signed integer format\n",
    "    with the bitwise operations. Note that, in order to perform the bitwise operation, the input\n",
    "    tensor has to be in the integer format.\n",
    "    '''\n",
    "    if num_bits == 1:\n",
    "        output = input*2-1\n",
    "    elif num_bits > 1:\n",
    "        mask = 2**(num_bits - 1) - 1\n",
    "        output = -(input & ~mask) + (input & mask)\n",
    "    return output\n",
    "\n",
    "\n",
    "def weight_conversion(model):\n",
    "    '''\n",
    "    Perform the weight data type conversion between:\n",
    "        signed integer <==> two's complement (unsigned integer)\n",
    "    Such conversion is used as additional step to ensure the conversion correctness\n",
    "\n",
    "    Note that, the data type conversion chosen is depend on the bits:\n",
    "        N_bits <= 8   .char()   --> torch.CharTensor(), 8-bit signed integer\n",
    "        N_bits <= 16  .short()  --> torch.shortTensor(), 16 bit signed integer\n",
    "        N_bits <= 32  .int()    --> torch.IntTensor(), 32 bit signed integer\n",
    "    '''\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, quan_Conv1d) or isinstance(m, quan_Linear):\n",
    "            w_bin = int2bin(m.weight.data, m.N_bits).short()\n",
    "            m.weight.data = bin2int(w_bin, m.N_bits).float()\n",
    "    return\n",
    "\n",
    "def count_ones(t, n_bits):\n",
    "    counter = 0\n",
    "    for i in range(n_bits):\n",
    "        counter += ((t & 2**i) // 2**i).sum()\n",
    "    return counter.item()\n",
    "\n",
    "\n",
    "def hamming_distance(model1, model2):\n",
    "    '''\n",
    "    Given two model whose structure, name and so on are identical.\n",
    "    The only difference between the model1 and model2 are the weight.\n",
    "    The function compute the hamming distance bewtween the bianry weights\n",
    "    (two's complement) of model1 and model2.\n",
    "    '''\n",
    "    # TODO: add the function check model1 and model2 are same structure\n",
    "    # check the keys of state_dict match or not.\n",
    "\n",
    "    H_dist = 0  # hamming distance counter\n",
    "\n",
    "    for name, module in model1.named_modules():\n",
    "        if isinstance(module, quan_Conv1d) or isinstance(module, quan_Linear):\n",
    "            # remember to convert the tensor into integer for bitwise operations\n",
    "            binW_model1 = int2bin(model1.state_dict()[name + '.weight'],\n",
    "                                  module.N_bits).short()\n",
    "            binW_model2 = int2bin(model2.state_dict()[name + '.weight'],\n",
    "                                  module.N_bits).short()\n",
    "            H_dist += count_ones(binW_model1 ^ binW_model2, module.N_bits)\n",
    "\n",
    "    return H_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895f209d-6392-4a4c-afce-986fa0128d9b",
   "metadata": {},
   "source": [
    "## Vẽ đồ thị MCC sau mỗi epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60ce8a7d-bea3-4e5b-a69e-dc8224dd1a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_mcc_vs_epoch(images_filename, x_data, y_data):\n",
    "    titles = [\"MCC\", \"ACC\", \"TPR\", \"F1-Score\"]\n",
    "    \n",
    "    for image_filename, title in zip(images_filename, titles):\n",
    "        if len(x_data) != len(y_data):\n",
    "            raise ValueError(\"x_data and y_data must have the same length.\")\n",
    "    \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(x_data, y_data, marker='o', linestyle='-', color='b', label='MCC')\n",
    "        plt.title(f'{title} after Epochs', fontsize=14) \n",
    "        plt.xlabel('Epoch', fontsize=12)\n",
    "        plt.ylabel(title, fontsize=12)\n",
    "        \n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        min_x, max_x = min(x_data), max(x_data)\n",
    "        plt.xticks(range(min_x, max_x + 1, 2))\n",
    "        # Save the plot as an image file\n",
    "        plt.savefig(image_filename)\n",
    "        plt.close()\n",
    "        print(f\"Plot saved as {image_filename}\")\n",
    "\n",
    "def plot_combined_metrics(image_filename, x_data, metric_dict):\n",
    "    colors = {\n",
    "        \"MCC\": \"blue\",\n",
    "        \"ACC\": \"orange\",\n",
    "        \"TPR\": \"green\",\n",
    "        \"F1\": \"red\"\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for metric in [\"MCC\", \"ACC\", \"TPR\", \"F1\"]:\n",
    "        y = [float(v) for v in metric_dict[metric]]\n",
    "        plt.plot(x_data, y, label=metric, color=colors[metric], linewidth=2)\n",
    "        plt.fill_between(x_data,\n",
    "                         [v * 0.95 for v in y],\n",
    "                         [v * 1.05 for v in y],\n",
    "                         alpha=0.2, color=colors[metric])\n",
    "\n",
    "    plt.xlabel(\"Epoch\", fontsize=12)\n",
    "    plt.ylabel(\"Metric Value (%)\", fontsize=12)\n",
    "    plt.title(\"Combined Metrics during Attack\", fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(image_filename)\n",
    "    plt.close()\n",
    "    print(f\"[Combined Plot] Saved as {image_filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf7df3e7-c55b-4690-be7c-cfd6f344f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def perform_attack(attacker, model, model_clean, train_loader, test_loader,\n",
    "                   N_iter, writer, file, csv_file, csv_save_path=None, attack_type=1,):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    iter_time = AverageMeter()\n",
    "    attack_time = AverageMeter()\n",
    "\n",
    "    for _, (data, target) in enumerate(train_loader):\n",
    "        if args.use_cuda:\n",
    "            target = target.cuda()\n",
    "            data = data.cuda()\n",
    "\n",
    "        data = data.unsqueeze(-1)  # Kích thước [512, 39, 1]\n",
    "        _, target = model(data).data.max(1)\n",
    "        break\n",
    "\n",
    "    val_mcc_top1, val_acc_top1, val_tpr_top1, val_f1score_top1, val_loss, output_summary = validate(test_loader, model, attacker.criterion, summary_output=True)\n",
    "    print(f'**Test** MCC: {val_mcc_top1:.3f}. Val_Loss: {val_loss:.3f}')\n",
    "    print(f'ACC: {val_acc_top1:.3f}.')\n",
    "    print(f'TPR: {val_tpr_top1:.3f}.')\n",
    "    print(f'F1-score: {val_f1score_top1:.3f}.')\n",
    "\n",
    "    tmp_df = pd.DataFrame(output_summary)\n",
    "    tmp_df['BFA iteration'] = 0\n",
    "    tmp_df.to_csv(os.path.join(args.save_path, 'output_summary_{}_BFA_0.csv'.format(args.arch)), index=False)\n",
    "\n",
    "    writer.add_scalar('attack/val_top1_acc', val_mcc_top1, 0)\n",
    "    writer.add_scalar('attack/val_loss', val_loss, 0)\n",
    "\n",
    "    print('Attack sample size is {}'.format(data.size()[0]))\n",
    "    end = time.time()\n",
    "    df = pd.DataFrame()\n",
    "    last_val_mcc_top1 = val_mcc_top1\n",
    "    last_val_acc_top1 = val_acc_top1\n",
    "    last_val_tpr_top1 = val_tpr_top1\n",
    "    last_val_f1score_top1 = val_f1score_top1\n",
    "\n",
    "    MCC_data = [val_mcc_top1]\n",
    "    epochs = [0]\n",
    "    all_attack_status = []\n",
    "    \n",
    "    metric_dict = {\n",
    "            \"MCC\": [val_mcc_top1],\n",
    "            \"ACC\": [val_acc_top1],\n",
    "            \"TPR\": [val_tpr_top1],\n",
    "            \"F1\": [val_f1score_top1]\n",
    "        }\n",
    "    \n",
    "    for i_iter in range(N_iter):\n",
    "        print('**********************************')        \n",
    "        if attack_type == 1:\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.progressive_bit_search(model, data, target, test_loader)\n",
    "            MCC_data.append(new_mcc['MCC'])\n",
    "            epochs.append(i_iter)\n",
    "        elif attack_type == 2:\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.random_flip_one_bit(model, test_loader)\n",
    "            MCC_data.append(new_mcc['MCC'])\n",
    "            epochs.append(i_iter)\n",
    "        elif attack_type == 3:\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.progressive_bit_search(model, data, target, test_loader)\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.random_flip_one_bit(model, test_loader)\n",
    "            MCC_data.append(new_mcc['MCC'])\n",
    "            epochs.append(i_iter)\n",
    "        elif attack_type == 4:\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.random_flip_one_bit(model, test_loader)\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.progressive_bit_search(model, data, target, test_loader)\n",
    "            MCC_data.append(new_mcc['MCC'])\n",
    "            epochs.append(i_iter)\n",
    "            \n",
    "        metric_dict[\"MCC\"].append(new_mcc[\"MCC\"])\n",
    "        metric_dict[\"ACC\"].append(new_mcc[\"Accuracy\"])\n",
    "        metric_dict[\"TPR\"].append(new_mcc[\"TPR\"])\n",
    "        metric_dict[\"F1\"].append(new_mcc[\"F1 Score\"])\n",
    "        \n",
    "        attack_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        h_dist = hamming_distance(model, model_clean)\n",
    "\n",
    "        if hasattr(attacker, \"loss_max\"):\n",
    "            losses.update(attacker.loss_max, data.size(0))\n",
    "\n",
    "        print('Iteration: [{:03d}/{:03d}]   Attack Time {attack_time.val:.3f} ({attack_time.avg:.3f})'.format(i_iter + 1, N_iter, attack_time=attack_time))\n",
    "\n",
    "        try:\n",
    "            print('Loss before attack: {:.4f}'.format(attacker.loss.item()))\n",
    "            print('Loss after attack: {:.4f}'.format(attacker.loss_max))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        print('Bit flips: {:.0f}'.format(attacker.bit_counter))\n",
    "        print('Hamming distance: {:.0f}'.format(h_dist))\n",
    "\n",
    "        writer.add_scalar('attack/bit_flip', attacker.bit_counter, i_iter + 1)\n",
    "        writer.add_scalar('attack/h_dist', h_dist, i_iter + 1)\n",
    "        writer.add_scalar('attack/sample_loss', losses.avg, i_iter + 1)\n",
    "\n",
    "        val_mcc_top1, val_acc_top1, val_tpr_top1, val_f1score_top1, val_loss, output_summary = validate(test_loader, model, attacker.criterion, summary_output=True)\n",
    "        print(f'**Test** MCC: {val_mcc_top1:.3f}. Val_Loss: {val_loss:.3f}')\n",
    "        print(f'ACC: {val_acc_top1:.3f}.')\n",
    "        print(f'TPR: {val_tpr_top1:.3f}.')\n",
    "        print(f'F1-score: {val_f1score_top1:.3f}.')\n",
    "        \n",
    "        tmp_df = pd.DataFrame(output_summary)\n",
    "        tmp_df['BFA iteration'] = i_iter + 1\n",
    "        tmp_df.to_csv(os.path.join(args.save_path, 'output_summary_{}_BFA_{}.csv'.format(args.arch, i_iter + 1)), index=False)\n",
    "\n",
    "        # last_val_mcc_top1 = val_mcc_top1\n",
    "        # last_val_acc_top1 = val_acc_top1\n",
    "        # last_val_tpr_top1 = val_tpr_top1\n",
    "        # last_val_f1score_top1 = val_f1score_top1\n",
    "        \n",
    "        mcc_drop = last_val_mcc_top1 - val_mcc_top1\n",
    "        last_val_mcc_top1 = val_mcc_top1\n",
    "\n",
    "        acc_drop = last_val_acc_top1 - val_acc_top1\n",
    "        last_val_acc_top1 = val_acc_top1\n",
    "\n",
    "        tpr_drop = last_val_tpr_top1 - val_tpr_top1\n",
    "        last_val_tpr_top1 = val_tpr_top1\n",
    "\n",
    "        f1score_drop = last_val_f1score_top1 - val_f1score_top1\n",
    "        last_val_f1score_top1 = val_f1score_top1\n",
    "\n",
    "        attack_last_status.append(round(val_mcc_top1, 5))\n",
    "        attack_last_status.append(round(mcc_drop, 5))\n",
    "        \n",
    "        attack_last_status.append(round(val_acc_top1, 5))\n",
    "        attack_last_status.append(round(acc_drop, 5))\n",
    "        \n",
    "        attack_last_status.append(round(val_tpr_top1, 5))\n",
    "        attack_last_status.append(round(tpr_drop, 5))\n",
    "        \n",
    "        attack_last_status.append(round(val_f1score_top1, 5))\n",
    "        attack_last_status.append(round(f1score_drop, 5))\n",
    "\n",
    "        for entry in attack_log:\n",
    "            entry.append(val_mcc_top1)\n",
    "            entry.append(mcc_drop)\n",
    "\n",
    "            entry.append(val_acc_top1)\n",
    "            entry.append(acc_drop)\n",
    "\n",
    "            entry.append(val_tpr_top1)\n",
    "            entry.append(tpr_drop)\n",
    "\n",
    "            entry.append(val_f1score_top1)\n",
    "            entry.append(f1score_drop)\n",
    "            \n",
    "        df = pd.concat([df, pd.DataFrame(attack_log)], ignore_index=True)\n",
    "\n",
    "        writer.add_scalar('attack/val_top1_acc', val_mcc_top1, i_iter + 1)\n",
    "        writer.add_scalar('attack/val_loss', val_loss, i_iter + 1)\n",
    "\n",
    "        iter_time.update(time.time() - end)\n",
    "        print('Iteration Time {iter_time.val:.3f} ({iter_time.avg:.3f})'.format(iter_time=iter_time))\n",
    "        end = time.time()\n",
    "\n",
    "        all_attack_status.append(attack_last_status)\n",
    "\n",
    "    column_list = ['module idx', 'bit-flip idx', 'module name', 'weight idx', 'weight before attack', 'weight after attack'\n",
    "                    , 'validation mcc', 'mcc drop'\n",
    "                    , \"ACC\", \"ACC Drop\"\n",
    "                    , \"TPR\", \"TPR Drop\"\n",
    "                    , \"F1-score\", \"F1-score Drop\",]\n",
    "    df.columns = column_list\n",
    "    df['trial seed'] = args.manualSeed\n",
    "\n",
    "    if csv_save_path is not None:\n",
    "        csv_file_name = 'attack_profile_{}.csv'.format(args.manualSeed)\n",
    "        df.to_csv(os.path.join(csv_save_path, csv_file_name), index=None)\n",
    "        \n",
    "    # Vẽ đồ thị với MCC\n",
    "    plot_mcc_vs_epoch(file, epochs, MCC_data)\n",
    "    \n",
    "    try:\n",
    "        if isinstance(file, list) and len(file) > 0:\n",
    "            first_image_name = os.path.basename(file[0])\n",
    "            suffix = first_image_name.split(\"_\", 1)[-1] if \"_\" in first_image_name else \"attack.png\"\n",
    "            combined_plot_path = os.path.join(os.path.dirname(file[0]), f\"combined_metrics_{suffix}\")\n",
    "        else:\n",
    "            combined_plot_path = \"combined_metrics.png\"\n",
    "\n",
    "        plot_combined_metrics(combined_plot_path, epochs, metric_dict)\n",
    "    except Exception as e:\n",
    "        print(f\"[Warning] Plotting combined metrics failed: {e}\")\n",
    "        \n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Ghi tiêu đề (nếu cần)\n",
    "        writer.writerow([\"Bit Counter\", \"Module\", \"Weight Before Attack\", \"Weight After Attack\"\n",
    "                         , \"MCC\", \"MCC Drop\"\n",
    "                         , \"ACC\", \"ACC Drop\"\n",
    "                         , \"TPR\", \"TPR Drop\"\n",
    "                         , \"F1-score\", \"F1-score Drop\",])\n",
    "        \n",
    "        # Ghi dữ liệu\n",
    "        writer.writerows(all_attack_status)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adfc613-8bbf-4eef-9108-2025db3e8a35",
   "metadata": {},
   "source": [
    "## Train CustomModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f57a1b3-406b-4238-a9d7-40de139a9083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC before attack: 0.7390823688130123\n",
      "Accuracy before attack: 0.7569846498270467\n",
      "TPR before attack: 0.6926142261733644\n",
      "F1-score before attack: 0.678880405326155\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Tải mô hình đã huấn luyện\n",
    "model_path = os.path.join(\"CustomModel\", \"best_model.pth\")\n",
    "# Kiểm tra xem tệp có tồn tại không\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Không tìm thấy mô hình tại: {model_path}\")\n",
    "\n",
    "trained_model = CustomModel()\n",
    "\n",
    "# Tải trọng số từ file best_model.pth\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC before attack: {results['MCC']}\")\n",
    "print(f\"Accuracy before attack: {results['Accuracy']}\")\n",
    "print(f\"TPR before attack: {results['TPR']}\")\n",
    "print(f\"F1-score before attack: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d41b45-6173-4820-9156-0b02557344d2",
   "metadata": {},
   "source": [
    "## Attack CustomModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d8058e6-93dd-406f-af0e-141023047ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.746. Val_Loss: 0.469\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.685.\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: fc1\n",
      "Iteration: [001/025]   Attack Time 6.762 (6.762)\n",
      "Loss before attack: 0.3428\n",
      "Loss after attack: 24.2991\n",
      "Bit flips: 1\n",
      "Hamming distance: 1\n",
      "**Test** MCC: 0.152. Val_Loss: 25.543\n",
      "ACC: 0.173.\n",
      "TPR: 0.121.\n",
      "F1-score: 0.108.\n",
      "Iteration Time 5.822 (5.822)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [002/025]   Attack Time 6.888 (6.825)\n",
      "Loss before attack: 24.2991\n",
      "Loss after attack: 416.0151\n",
      "Bit flips: 2\n",
      "Hamming distance: 1\n",
      "**Test** MCC: 0.162. Val_Loss: 405.143\n",
      "ACC: 0.184.\n",
      "TPR: 0.118.\n",
      "F1-score: 0.113.\n",
      "Iteration Time 6.070 (5.946)\n",
      "**********************************\n",
      "attacked module: stage_3.8.conv_a\n",
      "Iteration: [003/025]   Attack Time 10.758 (8.136)\n",
      "Loss before attack: 416.0151\n",
      "Loss after attack: 5661.1841\n",
      "Bit flips: 3\n",
      "Hamming distance: 2\n",
      "**Test** MCC: 0.149. Val_Loss: 5383.838\n",
      "ACC: 0.169.\n",
      "TPR: 0.111.\n",
      "F1-score: 0.104.\n",
      "Iteration Time 6.149 (6.014)\n",
      "**********************************\n",
      "attacked module: stage_2.4.conv_b\n",
      "Iteration: [004/025]   Attack Time 7.592 (8.000)\n",
      "Loss before attack: 5661.1841\n",
      "Loss after attack: 56340.8906\n",
      "Bit flips: 4\n",
      "Hamming distance: 3\n",
      "**Test** MCC: 0.088. Val_Loss: 53463.999\n",
      "ACC: 0.111.\n",
      "TPR: 0.077.\n",
      "F1-score: 0.063.\n",
      "Iteration Time 5.916 (5.989)\n",
      "**********************************\n",
      "attacked module: stage_1.0.conv_a\n",
      "Iteration: [005/025]   Attack Time 6.854 (7.771)\n",
      "Loss before attack: 56340.8906\n",
      "Loss after attack: 15085770.0000\n",
      "Bit flips: 5\n",
      "Hamming distance: 4\n",
      "**Test** MCC: 0.079. Val_Loss: 14328478.393\n",
      "ACC: 0.104.\n",
      "TPR: 0.077.\n",
      "F1-score: 0.063.\n",
      "Iteration Time 6.092 (6.010)\n",
      "**********************************\n",
      "attacked module: stage_2.4.conv_a\n",
      "Iteration: [006/025]   Attack Time 7.606 (7.743)\n",
      "Loss before attack: 15085770.0000\n",
      "Loss after attack: 2818206208.0000\n",
      "Bit flips: 6\n",
      "Hamming distance: 5\n",
      "**Test** MCC: 0.083. Val_Loss: 2676831162.539\n",
      "ACC: 0.085.\n",
      "TPR: 0.063.\n",
      "F1-score: 0.042.\n",
      "Iteration Time 6.077 (6.021)\n",
      "**********************************\n",
      "attacked module: stage_1.0.conv_b\n",
      "Iteration: [007/025]   Attack Time 7.188 (7.664)\n",
      "Loss before attack: 2818206208.0000\n",
      "Loss after attack: 294689538048.0000\n",
      "Bit flips: 7\n",
      "Hamming distance: 6\n",
      "**Test** MCC: 0.083. Val_Loss: 279924035235.805\n",
      "ACC: 0.085.\n",
      "TPR: 0.063.\n",
      "F1-score: 0.042.\n",
      "Iteration Time 6.452 (6.083)\n",
      "**********************************\n",
      "attacked module: stage_1.1.conv_b\n",
      "Iteration: [008/025]   Attack Time 6.826 (7.559)\n",
      "Loss before attack: 294689538048.0000\n",
      "Loss after attack: 7086434418688.0000\n",
      "Bit flips: 8\n",
      "Hamming distance: 7\n",
      "**Test** MCC: 0.094. Val_Loss: 6731711420706.901\n",
      "ACC: 0.071.\n",
      "TPR: 0.049.\n",
      "F1-score: 0.057.\n",
      "Iteration Time 6.287 (6.108)\n",
      "**********************************\n",
      "attacked module: stage_1.1.conv_a\n",
      "Iteration: [009/025]   Attack Time 6.887 (7.485)\n",
      "Loss before attack: 7086434418688.0000\n",
      "Loss after attack: 1118481894342656.0000\n",
      "Bit flips: 9\n",
      "Hamming distance: 8\n",
      "**Test** MCC: 0.077. Val_Loss: 1062503816342887.625\n",
      "ACC: 0.078.\n",
      "TPR: 0.059.\n",
      "F1-score: 0.044.\n",
      "Iteration Time 6.183 (6.116)\n",
      "**********************************\n",
      "attacked module: stage_2.6.conv_b\n",
      "Iteration: [010/025]   Attack Time 7.656 (7.502)\n",
      "Loss before attack: 1118481894342656.0000\n",
      "Loss after attack: 17891547412430848.0000\n",
      "Bit flips: 10\n",
      "Hamming distance: 9\n",
      "**Test** MCC: 0.089. Val_Loss: 16997210792825056.000\n",
      "ACC: 0.083.\n",
      "TPR: 0.056.\n",
      "F1-score: 0.050.\n",
      "Iteration Time 6.269 (6.132)\n",
      "**********************************\n",
      "attacked module: stage_2.6.conv_a\n",
      "Iteration: [011/025]   Attack Time 7.658 (7.516)\n",
      "Loss before attack: 17891547412430848.0000\n",
      "Loss after attack: 2475621073559748608.0000\n",
      "Bit flips: 11\n",
      "Hamming distance: 10\n",
      "**Test** MCC: 0.112. Val_Loss: 2351670993744924672.000\n",
      "ACC: 0.073.\n",
      "TPR: 0.053.\n",
      "F1-score: 0.054.\n",
      "Iteration Time 5.953 (6.115)\n",
      "**********************************\n",
      "attacked module: stage_1.2.conv_b\n",
      "Iteration: [012/025]   Attack Time 6.799 (7.456)\n",
      "Loss before attack: 2475621073559748608.0000\n",
      "Loss after attack: 38742831520966246400.0000\n",
      "Bit flips: 12\n",
      "Hamming distance: 11\n",
      "**Test** MCC: 0.058. Val_Loss: 36804909557710352384.000\n",
      "ACC: 0.040.\n",
      "TPR: 0.031.\n",
      "F1-score: 0.033.\n",
      "Iteration Time 6.158 (6.119)\n",
      "**********************************\n",
      "attacked module: stage_1.2.conv_a\n",
      "Iteration: [013/025]   Attack Time 6.785 (7.405)\n",
      "Loss before attack: 38742831520966246400.0000\n",
      "Loss after attack: 7201030061234101157888.0000\n",
      "Bit flips: 13\n",
      "Hamming distance: 12\n",
      "**Test** MCC: 0.108. Val_Loss: 6840237943692712738816.000\n",
      "ACC: 0.069.\n",
      "TPR: 0.050.\n",
      "F1-score: 0.052.\n",
      "Iteration Time 6.267 (6.130)\n",
      "**********************************\n",
      "attacked module: stage_1.13.conv_b\n",
      "Iteration: [014/025]   Attack Time 6.851 (7.365)\n",
      "Loss before attack: 7201030061234101157888.0000\n",
      "Loss after attack: 98420351205463627399168.0000\n",
      "Bit flips: 14\n",
      "Hamming distance: 13\n",
      "**Test** MCC: 0.035. Val_Loss: 93489833126990287208448.000\n",
      "ACC: 0.006.\n",
      "TPR: 0.013.\n",
      "F1-score: 0.013.\n",
      "Iteration Time 6.152 (6.132)\n",
      "**********************************\n",
      "attacked module: stage_1.13.conv_a\n",
      "Iteration: [015/025]   Attack Time 6.869 (7.332)\n",
      "Loss before attack: 98420351205463627399168.0000\n",
      "Loss after attack: 17378795189835238475825152.0000\n",
      "Bit flips: 15\n",
      "Hamming distance: 14\n",
      "**Test** MCC: 0.058. Val_Loss: 16508202490613792461815808.000\n",
      "ACC: 0.022.\n",
      "TPR: 0.021.\n",
      "F1-score: 0.023.\n",
      "Iteration Time 5.904 (6.117)\n",
      "**********************************\n",
      "attacked module: stage_1.4.conv_b\n",
      "Iteration: [016/025]   Attack Time 6.776 (7.297)\n",
      "Loss before attack: 17378795189835238475825152.0000\n",
      "Loss after attack: 189242749375456707786833920.0000\n",
      "Bit flips: 16\n",
      "Hamming distance: 15\n",
      "**Test** MCC: 0.075. Val_Loss: 179767452270706973455941632.000\n",
      "ACC: 0.032.\n",
      "TPR: 0.020.\n",
      "F1-score: 0.020.\n",
      "Iteration Time 6.191 (6.121)\n",
      "**********************************\n",
      "attacked module: stage_1.4.conv_a\n",
      "Iteration: [017/025]   Attack Time 7.181 (7.290)\n",
      "Loss before attack: 189242749375456707786833920.0000\n",
      "Loss after attack: 25546656797877162757209456640.0000\n",
      "Bit flips: 17\n",
      "Hamming distance: 16\n",
      "**Test** MCC: 0.048. Val_Loss: 24268055696377769740271091712.000\n",
      "ACC: 0.016.\n",
      "TPR: 0.018.\n",
      "F1-score: 0.020.\n",
      "Iteration Time 6.232 (6.128)\n",
      "**********************************\n",
      "attacked module: stage_1.3.conv_b\n",
      "Iteration: [018/025]   Attack Time 6.900 (7.269)\n",
      "Loss before attack: 25546656797877162757209456640.0000\n",
      "Loss after attack: 288033168946795486898464751616.0000\n",
      "Bit flips: 18\n",
      "Hamming distance: 17\n",
      "**Test** MCC: 0.017. Val_Loss: 273587185440159105271799480320.000\n",
      "ACC: 0.010.\n",
      "TPR: 0.012.\n",
      "F1-score: 0.011.\n",
      "Iteration Time 6.056 (6.124)\n",
      "**********************************\n",
      "attacked module: stage_1.3.conv_a\n",
      "Iteration: [019/025]   Attack Time 6.836 (7.246)\n",
      "Loss before attack: 288033168946795486898464751616.0000\n",
      "Loss after attack: 40961733732399215898534034276352.0000\n",
      "Bit flips: 19\n",
      "Hamming distance: 18\n",
      "**Test** MCC: 0.026. Val_Loss: 38908245360770554454207449006080.000\n",
      "ACC: 0.006.\n",
      "TPR: 0.012.\n",
      "F1-score: 0.012.\n",
      "Iteration Time 5.931 (6.114)\n",
      "**********************************\n",
      "attacked module: stage_2.14.conv_a\n",
      "Iteration: [020/025]   Attack Time 7.606 (7.264)\n",
      "Loss before attack: 40961733732399215898534034276352.0000\n",
      "Loss after attack: 444014623198697052299286636658688.0000\n",
      "Bit flips: 20\n",
      "Hamming distance: 19\n",
      "**Test** MCC: 0.024. Val_Loss: 422131248353753587058070727426048.000\n",
      "ACC: 0.006.\n",
      "TPR: 0.011.\n",
      "F1-score: 0.011.\n",
      "Iteration Time 6.232 (6.120)\n",
      "**********************************\n",
      "attacked module: stage_2.14.conv_b\n",
      "Iteration: [021/025]   Attack Time 7.629 (7.281)\n",
      "Loss before attack: 444014623198697052299286636658688.0000\n",
      "Loss after attack: 54047278644522145978552960057081856.0000\n",
      "Bit flips: 21\n",
      "Hamming distance: 20\n",
      "**Test** MCC: 0.025. Val_Loss: 51344435372174138169131389497114624.000\n",
      "ACC: 0.006.\n",
      "TPR: 0.010.\n",
      "F1-score: 0.010.\n",
      "Iteration Time 6.128 (6.120)\n",
      "**********************************\n",
      "attacked module: stage_2.9.conv_a\n",
      "Iteration: [022/025]   Attack Time 7.645 (7.298)\n",
      "Loss before attack: 54047278644522145978552960057081856.0000\n",
      "Loss after attack: 528748474210596537428888377291177984.0000\n",
      "Bit flips: 22\n",
      "Hamming distance: 21\n",
      "**Test** MCC: 0.024. Val_Loss: 502284042954049634586619349808709632.000\n",
      "ACC: 0.005.\n",
      "TPR: 0.010.\n",
      "F1-score: 0.010.\n",
      "Iteration Time 6.176 (6.123)\n",
      "**********************************\n",
      "attacked module: stage_1.5.conv_b\n",
      "Iteration: [023/025]   Attack Time 7.052 (7.287)\n",
      "Loss before attack: 528748474210596537428888377291177984.0000\n",
      "Loss after attack: inf\n",
      "Bit flips: 23\n",
      "Hamming distance: 22\n",
      "**Test** MCC: 0.022. Val_Loss: inf\n",
      "ACC: 0.005.\n",
      "TPR: 0.008.\n",
      "F1-score: 0.006.\n",
      "Iteration Time 6.209 (6.126)\n",
      "**********************************\n",
      "attacked module: fc1\n",
      "Iteration: [024/025]   Attack Time 7.714 (7.305)\n",
      "Loss before attack: inf\n",
      "Loss after attack: nan\n",
      "Bit flips: 25\n",
      "Hamming distance: 24\n",
      "**Test** MCC: 0.011. Val_Loss: nan\n",
      "ACC: 0.005.\n",
      "TPR: 0.007.\n",
      "F1-score: 0.006.\n",
      "Iteration Time 6.247 (6.131)\n",
      "**********************************\n",
      "Iteration: [025/025]   Attack Time 5.474 (7.232)\n",
      "Loss before attack: nan\n",
      "Loss after attack: nan\n",
      "Bit flips: 25\n",
      "Hamming distance: 24\n",
      "**Test** MCC: 0.011. Val_Loss: nan\n",
      "ACC: 0.005.\n",
      "TPR: 0.007.\n",
      "F1-score: 0.006.\n",
      "Iteration Time 6.082 (6.129)\n",
      "Plot saved as CustomModel/PBS_attack/MCC_PBS_attack.png\n",
      "Plot saved as CustomModel/PBS_attack/ACC_PBS_attack.png\n",
      "Plot saved as CustomModel/PBS_attack/TPR_PBS_attack.png\n",
      "Plot saved as CustomModel/PBS_attack/F1_PBS_attack.png\n",
      "[Combined Plot] Saved as CustomModel/PBS_attack/combined_metrics_PBS_attack.png\n",
      "MCC after 100 times PBS attack: 0.01070608517495955\n",
      "Accuracy after 100 times PBS attack: 0.004798649404985824\n",
      "TPR after 100 times PBS attack: 0.00744399041229326\n",
      "F1-score after 100 times PBS attack: 0.005557905046174616\n"
     ]
    }
   ],
   "source": [
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel\", \"PBS_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_paths = [os.path.join(attack_dir, f\"{metric}_PBS_attack.png\") \n",
    "                      for metric in [\"MCC\", \"ACC\", \"TPR\", \"F1\"]]\n",
    "# attack_image_path = os.path.join(attack_dir, \"PBS_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"PBS_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_paths,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path, \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 1,                  # Chế độ tấn công PBS\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "# best_mcc = validate_score(trained_model, test_loader)\n",
    "# print(f\"\\nMCC after 100 times PBS attack: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC after 100 times PBS attack: {results['MCC']}\")\n",
    "print(f\"Accuracy after 100 times PBS attack: {results['Accuracy']}\")\n",
    "print(f\"TPR after 100 times PBS attack: {results['TPR']}\")\n",
    "print(f\"F1-score after 100 times PBS attack: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31bd74aa-83fe-4388-9e48-e018219c5c31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: stage_2.15.conv_a\n",
      "attacked weight index: 11684\n",
      "weight before attack: tensor(0.0333, device='cuda:0')\n",
      "weight after attack: tensor(4., device='cuda:0')\n",
      "Iteration: [001/025]   Attack Time 5.621 (5.621)\n",
      "Bit flips: 1\n",
      "Hamming distance: 1\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.088 (6.088)\n",
      "**********************************\n",
      "attacked module: stage_1.15.conv_b\n",
      "attacked weight index: 784\n",
      "weight before attack: tensor(0.1283, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "Iteration: [002/025]   Attack Time 5.680 (5.651)\n",
      "Bit flips: 2\n",
      "Hamming distance: 2\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.063 (6.076)\n",
      "**********************************\n",
      "attacked module: stage_1.9.conv_a\n",
      "attacked weight index: 509\n",
      "weight before attack: tensor(-0.1215, device='cuda:0')\n",
      "weight after attack: tensor(-2., device='cuda:0')\n",
      "Iteration: [003/025]   Attack Time 5.543 (5.615)\n",
      "Bit flips: 3\n",
      "Hamming distance: 3\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.221 (6.124)\n",
      "**********************************\n",
      "attacked module: stage_2.7.conv_a\n",
      "attacked weight index: 999\n",
      "weight before attack: tensor(0.0887, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "Iteration: [004/025]   Attack Time 5.529 (5.593)\n",
      "Bit flips: 4\n",
      "Hamming distance: 4\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.019 (6.098)\n",
      "**********************************\n",
      "attacked module: stage_2.12.conv_b\n",
      "attacked weight index: 11827\n",
      "weight before attack: tensor(-0.2469, device='cuda:0')\n",
      "weight after attack: tensor(-5., device='cuda:0')\n",
      "Iteration: [005/025]   Attack Time 5.609 (5.596)\n",
      "Bit flips: 5\n",
      "Hamming distance: 5\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.314 (6.141)\n",
      "**********************************\n",
      "attacked module: stage_3.13.conv_b\n",
      "attacked weight index: 4991\n",
      "weight before attack: tensor(0.0714, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "Iteration: [006/025]   Attack Time 5.466 (5.575)\n",
      "Bit flips: 6\n",
      "Hamming distance: 6\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.007 (6.119)\n",
      "**********************************\n",
      "attacked module: stage_1.7.conv_b\n",
      "attacked weight index: 1915\n",
      "weight before attack: tensor(-0.0574, device='cuda:0')\n",
      "weight after attack: tensor(-17., device='cuda:0')\n",
      "Iteration: [007/025]   Attack Time 5.535 (5.569)\n",
      "Bit flips: 7\n",
      "Hamming distance: 7\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.302 (6.145)\n",
      "**********************************\n",
      "attacked module: stage_3.7.conv_b\n",
      "attacked weight index: 23252\n",
      "weight before attack: tensor(0.0261, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "Iteration: [008/025]   Attack Time 5.624 (5.576)\n",
      "Bit flips: 8\n",
      "Hamming distance: 8\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 5.962 (6.122)\n",
      "**********************************\n",
      "attacked module: stage_3.3.conv_b\n",
      "attacked weight index: 20966\n",
      "weight before attack: tensor(0.0856, device='cuda:0')\n",
      "weight after attack: tensor(64., device='cuda:0')\n",
      "Iteration: [009/025]   Attack Time 5.632 (5.582)\n",
      "Bit flips: 9\n",
      "Hamming distance: 9\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.259 (6.137)\n",
      "**********************************\n",
      "attacked module: stage_3.9.conv_b\n",
      "attacked weight index: 17844\n",
      "weight before attack: tensor(0.0014, device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "Iteration: [010/025]   Attack Time 5.654 (5.589)\n",
      "Bit flips: 10\n",
      "Hamming distance: 10\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.159 (6.139)\n",
      "**********************************\n",
      "attacked module: stage_2.4.conv_b\n",
      "attacked weight index: 4276\n",
      "weight before attack: tensor(-0.1492, device='cuda:0')\n",
      "weight after attack: tensor(-33., device='cuda:0')\n",
      "Iteration: [011/025]   Attack Time 5.632 (5.593)\n",
      "Bit flips: 11\n",
      "Hamming distance: 11\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.090 (6.135)\n",
      "**********************************\n",
      "attacked module: stage_1.1.conv_a\n",
      "attacked weight index: 2528\n",
      "weight before attack: tensor(0.2548, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "Iteration: [012/025]   Attack Time 5.673 (5.600)\n",
      "Bit flips: 12\n",
      "Hamming distance: 12\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.165 (6.137)\n",
      "**********************************\n",
      "attacked module: stage_2.4.conv_b\n",
      "attacked weight index: 8519\n",
      "weight before attack: tensor(0.0241, device='cuda:0')\n",
      "weight after attack: tensor(1., device='cuda:0')\n",
      "Iteration: [013/025]   Attack Time 5.604 (5.600)\n",
      "Bit flips: 13\n",
      "Hamming distance: 13\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.181 (6.141)\n",
      "**********************************\n",
      "attacked module: stage_1.15.conv_b\n",
      "attacked weight index: 1082\n",
      "weight before attack: tensor(0.0941, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "Iteration: [014/025]   Attack Time 5.650 (5.604)\n",
      "Bit flips: 14\n",
      "Hamming distance: 14\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.208 (6.146)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 3238\n",
      "weight before attack: tensor(0.0218, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "Iteration: [015/025]   Attack Time 5.437 (5.593)\n",
      "Bit flips: 15\n",
      "Hamming distance: 14\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.109 (6.143)\n",
      "**********************************\n",
      "attacked module: stage_1.4.conv_a\n",
      "attacked weight index: 2017\n",
      "weight before attack: tensor(0.0948, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "Iteration: [016/025]   Attack Time 5.530 (5.589)\n",
      "Bit flips: 16\n",
      "Hamming distance: 15\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 5.967 (6.132)\n",
      "**********************************\n",
      "attacked module: stage_2.1.conv_a\n",
      "attacked weight index: 2052\n",
      "weight before attack: tensor(0.0814, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "Iteration: [017/025]   Attack Time 5.502 (5.584)\n",
      "Bit flips: 17\n",
      "Hamming distance: 16\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.333 (6.144)\n",
      "**********************************\n",
      "attacked module: stage_2.0.conv_a\n",
      "attacked weight index: 2549\n",
      "weight before attack: tensor(-0.0440, device='cuda:0')\n",
      "weight after attack: tensor(-9., device='cuda:0')\n",
      "Iteration: [018/025]   Attack Time 5.505 (5.579)\n",
      "Bit flips: 18\n",
      "Hamming distance: 17\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.028 (6.138)\n",
      "**********************************\n",
      "attacked module: stage_3.10.conv_a\n",
      "attacked weight index: 18872\n",
      "weight before attack: tensor(-0.0091, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "Iteration: [019/025]   Attack Time 5.471 (5.573)\n",
      "Bit flips: 19\n",
      "Hamming distance: 18\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.367 (6.150)\n",
      "**********************************\n",
      "attacked module: stage_1.9.conv_b\n",
      "attacked weight index: 892\n",
      "weight before attack: tensor(0.1717, device='cuda:0')\n",
      "weight after attack: tensor(1., device='cuda:0')\n",
      "Iteration: [020/025]   Attack Time 5.743 (5.582)\n",
      "Bit flips: 20\n",
      "Hamming distance: 19\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Iteration Time 6.327 (6.158)\n",
      "**********************************\n",
      "attacked module: stage_2.15.conv_a\n",
      "attacked weight index: 1909\n",
      "weight before attack: tensor(0.0477, device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "Iteration: [021/025]   Attack Time 5.483 (5.577)\n",
      "Bit flips: 21\n",
      "Hamming distance: 20\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.699.\n",
      "F1-score: 0.683.\n",
      "Iteration Time 6.080 (6.155)\n",
      "**********************************\n",
      "attacked module: stage_1.12.conv_a\n",
      "attacked weight index: 1097\n",
      "weight before attack: tensor(0.0532, device='cuda:0')\n",
      "weight after attack: tensor(4., device='cuda:0')\n",
      "Iteration: [022/025]   Attack Time 5.536 (5.575)\n",
      "Bit flips: 22\n",
      "Hamming distance: 21\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.699.\n",
      "F1-score: 0.683.\n",
      "Iteration Time 5.988 (6.147)\n",
      "**********************************\n",
      "attacked module: stage_1.10.conv_a\n",
      "attacked weight index: 1737\n",
      "weight before attack: tensor(-0.1771, device='cuda:0')\n",
      "weight after attack: tensor(-5., device='cuda:0')\n",
      "Iteration: [023/025]   Attack Time 5.549 (5.574)\n",
      "Bit flips: 23\n",
      "Hamming distance: 22\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.699.\n",
      "F1-score: 0.683.\n",
      "Iteration Time 6.057 (6.143)\n",
      "**********************************\n",
      "attacked module: stage_2.14.conv_b\n",
      "attacked weight index: 3464\n",
      "weight before attack: tensor(-0.0094, device='cuda:0')\n",
      "weight after attack: tensor(-2., device='cuda:0')\n",
      "Iteration: [024/025]   Attack Time 5.593 (5.575)\n",
      "Bit flips: 24\n",
      "Hamming distance: 23\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.699.\n",
      "F1-score: 0.683.\n",
      "Iteration Time 6.057 (6.140)\n",
      "**********************************\n",
      "attacked module: stage_1.2.conv_a\n",
      "attacked weight index: 1256\n",
      "weight before attack: tensor(0.0542, device='cuda:0')\n",
      "weight after attack: tensor(32., device='cuda:0')\n",
      "Iteration: [025/025]   Attack Time 5.591 (5.576)\n",
      "Bit flips: 25\n",
      "Hamming distance: 24\n",
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.699.\n",
      "F1-score: 0.683.\n",
      "Iteration Time 6.240 (6.144)\n",
      "Plot saved as CustomModel/RandomFlip_attack/MCC_RandomFlip_attack.png\n",
      "Plot saved as CustomModel/RandomFlip_attack/ACC_RandomFlip_attack.png\n",
      "Plot saved as CustomModel/RandomFlip_attack/TPR_RandomFlip_attack.png\n",
      "Plot saved as CustomModel/RandomFlip_attack/F1_RandomFlip_attack.png\n",
      "[Combined Plot] Saved as CustomModel/RandomFlip_attack/combined_metrics_RandomFlip_attack.png\n",
      "MCC after 100 times random attack: 0.7461876369879045\n",
      "Accuracy after 100 times random attack: 0.7626182458780244\n",
      "TPR after 100 times random attack: 0.6993216294402914\n",
      "F1-score after 100 times random attack: 0.6834406560508209\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Tải mô hình đã huấn luyện\n",
    "model_path = os.path.join(\"CustomModel\", \"best_model.pth\")\n",
    "\n",
    "trained_model = CustomModel()\n",
    "\n",
    "# Tải trọng số từ file best_model.pth\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel\", \"RandomFlip_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_paths = [os.path.join(attack_dir, f\"{metric}_RandomFlip_attack.png\") \n",
    "                      for metric in [\"MCC\", \"ACC\", \"TPR\", \"F1\"]]\n",
    "# attack_image_path = os.path.join(attack_dir, \"RandomFlip_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"RandomFlip_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_paths,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path, \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 2,                  # Chế độ tấn công random\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "\n",
    "# best_mcc = validate_score(trained_model ,test_loader)\n",
    "# print(f\"\\nMCC after 100 times random attack: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC after 100 times random attack: {results['MCC']}\")\n",
    "print(f\"Accuracy after 100 times random attack: {results['Accuracy']}\")\n",
    "print(f\"TPR after 100 times random attack: {results['TPR']}\")\n",
    "print(f\"F1-score after 100 times random attack: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0b8375d-ecc2-40d2-b41a-97f243b4c903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: fc1\n",
      "attacked module: stage_1.12.conv_a\n",
      "attacked weight index: 842\n",
      "weight before attack: tensor(0.0083, device='cuda:0')\n",
      "weight after attack: tensor(32., device='cuda:0')\n",
      "Iteration: [001/025]   Attack Time 12.265 (12.265)\n",
      "Loss before attack: 0.3747\n",
      "Loss after attack: 12.9431\n",
      "Bit flips: 2\n",
      "Hamming distance: 2\n",
      "**Test** MCC: 0.028. Val_Loss: 12.955\n",
      "ACC: 0.017.\n",
      "TPR: 0.052.\n",
      "F1-score: 0.028.\n",
      "Iteration Time 6.058 (6.058)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: stage_3.0.conv_b\n",
      "attacked weight index: 23486\n",
      "weight before attack: tensor(-0.0558, device='cuda:0')\n",
      "weight after attack: tensor(-2., device='cuda:0')\n",
      "Iteration: [002/025]   Attack Time 12.354 (12.310)\n",
      "Loss before attack: 12.9431\n",
      "Loss after attack: 188.5564\n",
      "Bit flips: 4\n",
      "Hamming distance: 3\n",
      "**Test** MCC: 0.018. Val_Loss: 187.239\n",
      "ACC: 0.021.\n",
      "TPR: 0.063.\n",
      "F1-score: 0.025.\n",
      "Iteration Time 6.001 (6.030)\n",
      "**********************************\n",
      "attacked module: stage_3.8.conv_a\n",
      "attacked module: stage_2.7.conv_a\n",
      "attacked weight index: 1070\n",
      "weight before attack: tensor(-0.0801, device='cuda:0')\n",
      "weight after attack: tensor(-2., device='cuda:0')\n",
      "Iteration: [003/025]   Attack Time 16.509 (13.709)\n",
      "Loss before attack: 188.5564\n",
      "Loss after attack: 2794.7539\n",
      "Bit flips: 6\n",
      "Hamming distance: 5\n",
      "**Test** MCC: 0.026. Val_Loss: 2677.377\n",
      "ACC: 0.014.\n",
      "TPR: 0.032.\n",
      "F1-score: 0.020.\n",
      "Iteration Time 6.103 (6.054)\n",
      "**********************************\n",
      "attacked module: stage_3.8.conv_b\n",
      "attacked module: stage_1.3.conv_b\n",
      "attacked weight index: 1874\n",
      "weight before attack: tensor(-0.1049, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "Iteration: [004/025]   Attack Time 16.331 (14.365)\n",
      "Loss before attack: 2794.7539\n",
      "Loss after attack: 171889.4062\n",
      "Bit flips: 8\n",
      "Hamming distance: 7\n",
      "**Test** MCC: 0.026. Val_Loss: 169054.386\n",
      "ACC: 0.015.\n",
      "TPR: 0.043.\n",
      "F1-score: 0.020.\n",
      "Iteration Time 6.181 (6.086)\n",
      "**********************************\n",
      "attacked module: stage_2.4.conv_b\n",
      "attacked module: stage_2.6.conv_b\n",
      "attacked weight index: 10923\n",
      "weight before attack: tensor(-0.0165, device='cuda:0')\n",
      "weight after attack: tensor(-17., device='cuda:0')\n",
      "Iteration: [005/025]   Attack Time 13.496 (14.191)\n",
      "Loss before attack: 171889.4062\n",
      "Loss after attack: 1680903.5000\n",
      "Bit flips: 10\n",
      "Hamming distance: 9\n",
      "**Test** MCC: 0.041. Val_Loss: 1655093.927\n",
      "ACC: 0.020.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.025.\n",
      "Iteration Time 6.213 (6.112)\n",
      "**********************************\n",
      "attacked module: stage_2.4.conv_a\n",
      "attacked module: stage_1.10.conv_b\n",
      "attacked weight index: 1297\n",
      "weight before attack: tensor(-0.1977, device='cuda:0')\n",
      "weight after attack: tensor(-3., device='cuda:0')\n",
      "Iteration: [006/025]   Attack Time 12.981 (13.989)\n",
      "Loss before attack: 1680903.5000\n",
      "Loss after attack: 362772736.0000\n",
      "Bit flips: 12\n",
      "Hamming distance: 11\n",
      "**Test** MCC: 0.026. Val_Loss: 356573143.200\n",
      "ACC: 0.015.\n",
      "TPR: 0.043.\n",
      "F1-score: 0.019.\n",
      "Iteration Time 5.878 (6.073)\n",
      "**********************************\n",
      "attacked module: stage_2.6.conv_b\n",
      "attacked module: stage_1.4.conv_b\n",
      "attacked weight index: 1416\n",
      "weight before attack: tensor(0.0017, device='cuda:0')\n",
      "weight after attack: tensor(1., device='cuda:0')\n",
      "Iteration: [007/025]   Attack Time 13.214 (13.878)\n",
      "Loss before attack: 362834176.0000\n",
      "Loss after attack: 6644941824.0000\n",
      "Bit flips: 14\n",
      "Hamming distance: 13\n",
      "**Test** MCC: 0.034. Val_Loss: 6530341897.583\n",
      "ACC: 0.015.\n",
      "TPR: 0.043.\n",
      "F1-score: 0.020.\n",
      "Iteration Time 6.049 (6.069)\n",
      "**********************************\n",
      "attacked module: stage_2.6.conv_a\n",
      "attacked module: stage_2.14.conv_b\n",
      "attacked weight index: 5059\n",
      "weight before attack: tensor(-0.3029, device='cuda:0')\n",
      "weight after attack: tensor(-3., device='cuda:0')\n",
      "Iteration: [008/025]   Attack Time 13.053 (13.775)\n",
      "Loss before attack: 6644941824.0000\n",
      "Loss after attack: 927185502208.0000\n",
      "Bit flips: 16\n",
      "Hamming distance: 15\n",
      "**Test** MCC: 0.025. Val_Loss: 911133659492.538\n",
      "ACC: 0.014.\n",
      "TPR: 0.043.\n",
      "F1-score: 0.019.\n",
      "Iteration Time 6.123 (6.076)\n",
      "**********************************\n",
      "attacked module: stage_2.14.conv_a\n",
      "attacked module: stage_3.4.conv_a\n",
      "attacked weight index: 10861\n",
      "weight before attack: tensor(-0.2358, device='cuda:0')\n",
      "weight after attack: tensor(-33., device='cuda:0')\n",
      "Iteration: [009/025]   Attack Time 13.315 (13.724)\n",
      "Loss before attack: 927185502208.0000\n",
      "Loss after attack: 10218471686144.0000\n",
      "Bit flips: 18\n",
      "Hamming distance: 17\n",
      "**Test** MCC: 0.025. Val_Loss: 10041717127726.258\n",
      "ACC: 0.014.\n",
      "TPR: 0.042.\n",
      "F1-score: 0.019.\n",
      "Iteration Time 6.101 (6.079)\n",
      "**********************************\n",
      "attacked module: stage_2.14.conv_b\n",
      "attacked module: stage_3.4.conv_b\n",
      "attacked weight index: 7010\n",
      "weight before attack: tensor(-0.0572, device='cuda:0')\n",
      "weight after attack: tensor(-9., device='cuda:0')\n",
      "Iteration: [010/025]   Attack Time 13.238 (13.676)\n",
      "Loss before attack: 10218471686144.0000\n",
      "Loss after attack: 1243622276071424.0000\n",
      "Bit flips: 20\n",
      "Hamming distance: 19\n",
      "**Test** MCC: 0.025. Val_Loss: 1222155356191157.250\n",
      "ACC: 0.014.\n",
      "TPR: 0.042.\n",
      "F1-score: 0.019.\n",
      "Iteration Time 6.027 (6.074)\n",
      "**********************************\n",
      "attacked module: stage_2.9.conv_a\n",
      "attacked module: stage_2.3.conv_a\n",
      "attacked weight index: 1714\n",
      "weight before attack: tensor(0.0277, device='cuda:0')\n",
      "weight after attack: tensor(64., device='cuda:0')\n",
      "Iteration: [011/025]   Attack Time 13.238 (13.636)\n",
      "Loss before attack: 1243622276071424.0000\n",
      "Loss after attack: 11618833575968768.0000\n",
      "Bit flips: 22\n",
      "Hamming distance: 21\n",
      "**Test** MCC: 0.024. Val_Loss: 11418147282309038.000\n",
      "ACC: 0.014.\n",
      "TPR: 0.042.\n",
      "F1-score: 0.018.\n",
      "Iteration Time 5.970 (6.064)\n",
      "**********************************\n",
      "attacked module: stage_2.9.conv_b\n",
      "attacked module: stage_2.9.conv_a\n",
      "attacked weight index: 9738\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-9., device='cuda:0')\n",
      "Iteration: [012/025]   Attack Time 13.157 (13.596)\n",
      "Loss before attack: 11618833575968768.0000\n",
      "Loss after attack: 2459085243311718400.0000\n",
      "Bit flips: 24\n",
      "Hamming distance: 23\n",
      "**Test** MCC: 0.024. Val_Loss: 2416482111029130752.000\n",
      "ACC: 0.014.\n",
      "TPR: 0.042.\n",
      "F1-score: 0.018.\n",
      "Iteration Time 6.004 (6.059)\n",
      "**********************************\n",
      "attacked module: stage_3.9.conv_a\n",
      "attacked module: stage_3.15.conv_a\n",
      "attacked weight index: 3461\n",
      "weight before attack: tensor(-0.0799, device='cuda:0')\n",
      "weight after attack: tensor(-3., device='cuda:0')\n",
      "Iteration: [013/025]   Attack Time 15.971 (13.779)\n",
      "Loss before attack: 2459085243311718400.0000\n",
      "Loss after attack: 20266774467260186624.0000\n",
      "Bit flips: 26\n",
      "Hamming distance: 25\n",
      "**Test** MCC: 0.019. Val_Loss: 18165345813238863872.000\n",
      "ACC: 0.017.\n",
      "TPR: 0.054.\n",
      "F1-score: 0.019.\n",
      "Iteration Time 6.040 (6.058)\n",
      "**********************************\n",
      "attacked module: stage_2.12.conv_b\n",
      "attacked module: stage_3.11.conv_a\n",
      "attacked weight index: 37015\n",
      "weight before attack: tensor(-0.2249, device='cuda:0')\n",
      "weight after attack: tensor(-9., device='cuda:0')\n",
      "Iteration: [014/025]   Attack Time 13.717 (13.774)\n",
      "Loss before attack: 20266774467260186624.0000\n",
      "Loss after attack: 158392531280480698368.0000\n",
      "Bit flips: 28\n",
      "Hamming distance: 27\n",
      "**Test** MCC: 0.027. Val_Loss: 141976849458699976704.000\n",
      "ACC: 0.018.\n",
      "TPR: 0.055.\n",
      "F1-score: 0.019.\n",
      "Iteration Time 6.219 (6.069)\n",
      "**********************************\n",
      "attacked module: stage_2.12.conv_a\n",
      "attacked module: stage_3.6.conv_a\n",
      "attacked weight index: 3146\n",
      "weight before attack: tensor(0.0724, device='cuda:0')\n",
      "weight after attack: tensor(-128., device='cuda:0')\n",
      "Iteration: [015/025]   Attack Time 13.109 (13.730)\n",
      "Loss before attack: 158392531280480698368.0000\n",
      "Loss after attack: 20576503092892500230144.0000\n",
      "Bit flips: 30\n",
      "Hamming distance: 29\n",
      "**Test** MCC: 0.019. Val_Loss: 18443196327266934063104.000\n",
      "ACC: 0.017.\n",
      "TPR: 0.055.\n",
      "F1-score: 0.019.\n",
      "Iteration Time 5.879 (6.056)\n",
      "**********************************\n",
      "attacked module: stage_2.11.conv_b\n",
      "attacked module: stage_3.15.conv_b\n",
      "attacked weight index: 5174\n",
      "weight before attack: tensor(0.0330, device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "Iteration: [016/025]   Attack Time 13.193 (13.696)\n",
      "Loss before attack: 20576503092892500230144.0000\n",
      "Loss after attack: 150545076343044531290112.0000\n",
      "Bit flips: 32\n",
      "Hamming distance: 31\n",
      "**Test** MCC: 0.012. Val_Loss: 134959752516038484295680.000\n",
      "ACC: 0.010.\n",
      "TPR: 0.042.\n",
      "F1-score: 0.004.\n",
      "Iteration Time 5.996 (6.053)\n",
      "**********************************\n",
      "attacked module: stage_2.11.conv_a\n",
      "attacked module: stage_3.6.conv_a\n",
      "attacked weight index: 30748\n",
      "weight before attack: tensor(0.2855, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "Iteration: [017/025]   Attack Time 13.018 (13.656)\n",
      "Loss before attack: 150545076343044531290112.0000\n",
      "Loss after attack: 38316154084772795767586816.0000\n",
      "Bit flips: 34\n",
      "Hamming distance: 33\n",
      "**Test** MCC: 0.019. Val_Loss: 34345201984706452593311744.000\n",
      "ACC: 0.017.\n",
      "TPR: 0.054.\n",
      "F1-score: 0.019.\n",
      "Iteration Time 5.893 (6.043)\n",
      "**********************************\n",
      "attacked module: stage_2.15.conv_b\n",
      "attacked module: stage_1.12.conv_b\n",
      "attacked weight index: 235\n",
      "weight before attack: tensor(-0.0557, device='cuda:0')\n",
      "weight after attack: tensor(-17., device='cuda:0')\n",
      "Iteration: [018/025]   Attack Time 13.192 (13.631)\n",
      "Loss before attack: 38316154084772795767586816.0000\n",
      "Loss after attack: 255195504142654909936828416.0000\n",
      "Bit flips: 36\n",
      "Hamming distance: 35\n",
      "**Test** MCC: 0.026. Val_Loss: 228742961035868345527697408.000\n",
      "ACC: 0.018.\n",
      "TPR: 0.055.\n",
      "F1-score: 0.020.\n",
      "Iteration Time 5.954 (6.038)\n",
      "**********************************\n",
      "attacked module: stage_2.15.conv_a\n",
      "attacked module: stage_3.12.conv_b\n",
      "attacked weight index: 36932\n",
      "weight before attack: tensor(0.0103, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "Iteration: [019/025]   Attack Time 12.730 (13.583)\n",
      "Loss before attack: 255195504142654909936828416.0000\n",
      "Loss after attack: 36287773810493828188665282560.0000\n",
      "Bit flips: 38\n",
      "Hamming distance: 37\n",
      "**Test** MCC: 0.019. Val_Loss: 32524952016120747194885079040.000\n",
      "ACC: 0.017.\n",
      "TPR: 0.054.\n",
      "F1-score: 0.019.\n",
      "Iteration Time 5.964 (6.034)\n",
      "**********************************\n",
      "attacked module: stage_3.0.conv_a\n",
      "attacked module: stage_1.12.conv_b\n",
      "attacked weight index: 2556\n",
      "weight before attack: tensor(-0.0365, device='cuda:0')\n",
      "weight after attack: tensor(-2., device='cuda:0')\n",
      "Iteration: [020/025]   Attack Time 14.223 (13.615)\n",
      "Loss before attack: 36287773810493828188665282560.0000\n",
      "Loss after attack: 233106021011389371395887595520.0000\n",
      "Bit flips: 40\n",
      "Hamming distance: 39\n",
      "**Test** MCC: 0.019. Val_Loss: 208945221821816386675678380032.000\n",
      "ACC: 0.017.\n",
      "TPR: 0.054.\n",
      "F1-score: 0.019.\n",
      "Iteration Time 6.101 (6.038)\n",
      "**********************************\n",
      "attacked module: stage_3.0.conv_b\n",
      "attacked module: stage_1.13.conv_b\n",
      "attacked weight index: 1066\n",
      "weight before attack: tensor(-0.2911, device='cuda:0')\n",
      "weight after attack: tensor(-3., device='cuda:0')\n",
      "Iteration: [021/025]   Attack Time 16.173 (13.737)\n",
      "Loss before attack: 233106021011389371395887595520.0000\n",
      "Loss after attack: 25436321500645871355621416108032.0000\n",
      "Bit flips: 42\n",
      "Hamming distance: 41\n",
      "**Test** MCC: 0.019. Val_Loss: 22799521398934665832445792747520.000\n",
      "ACC: 0.017.\n",
      "TPR: 0.054.\n",
      "F1-score: 0.019.\n",
      "Iteration Time 6.053 (6.038)\n",
      "**********************************\n",
      "attacked module: stage_2.10.conv_b\n",
      "attacked module: stage_2.7.conv_b\n",
      "attacked weight index: 10036\n",
      "weight before attack: tensor(0.0332, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "Iteration: [022/025]   Attack Time 13.213 (13.713)\n",
      "Loss before attack: 25436321500645871355621416108032.0000\n",
      "Loss after attack: 155193008699500286695086435074048.0000\n",
      "Bit flips: 44\n",
      "Hamming distance: 43\n",
      "**Test** MCC: 0.035. Val_Loss: 139117982619520871398236659646464.000\n",
      "ACC: 0.022.\n",
      "TPR: 0.057.\n",
      "F1-score: 0.021.\n",
      "Iteration Time 6.354 (6.053)\n",
      "**********************************\n",
      "attacked module: stage_2.10.conv_a\n",
      "attacked module: stage_2.13.conv_a\n",
      "attacked weight index: 1040\n",
      "weight before attack: tensor(-0.1460, device='cuda:0')\n",
      "weight after attack: tensor(-9., device='cuda:0')\n",
      "Iteration: [023/025]   Attack Time 12.981 (13.681)\n",
      "Loss before attack: 155193008699500286695086435074048.0000\n",
      "Loss after attack: 34467286122681314605625671048757248.0000\n",
      "Bit flips: 46\n",
      "Hamming distance: 45\n",
      "**Test** MCC: 0.019. Val_Loss: 30898285235515503574300356568416256.000\n",
      "ACC: 0.017.\n",
      "TPR: 0.054.\n",
      "F1-score: 0.019.\n",
      "Iteration Time 6.091 (6.054)\n",
      "**********************************\n",
      "attacked module: stage_3.2.conv_b\n",
      "attacked module: stage_2.13.conv_b\n",
      "attacked weight index: 11454\n",
      "weight before attack: tensor(0.1327, device='cuda:0')\n",
      "weight after attack: tensor(1., device='cuda:0')\n",
      "Iteration: [024/025]   Attack Time 16.193 (13.786)\n",
      "Loss before attack: 34467286122681314605625671048757248.0000\n",
      "Loss after attack: 193091510482858187348637590141009920.0000\n",
      "Bit flips: 48\n",
      "Hamming distance: 47\n",
      "**Test** MCC: 0.025. Val_Loss: 173083927121015346875106826909646848.000\n",
      "ACC: 0.016.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.009.\n",
      "Iteration Time 6.102 (6.056)\n",
      "**********************************\n",
      "attacked module: stage_2.5.conv_b\n",
      "attacked module: stage_3.4.conv_b\n",
      "attacked weight index: 47255\n",
      "weight before attack: tensor(0.0087, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "Iteration: [025/025]   Attack Time 13.060 (13.757)\n",
      "Loss before attack: 193091510482858187348637590141009920.0000\n",
      "Loss after attack: 1060100544297736829519775795878297600.0000\n",
      "Bit flips: 50\n",
      "Hamming distance: 49\n",
      "**Test** MCC: 0.063. Val_Loss: 950234516524273010661831874715844608.000\n",
      "ACC: 0.019.\n",
      "TPR: 0.047.\n",
      "F1-score: 0.012.\n",
      "Iteration Time 6.022 (6.055)\n",
      "Plot saved as CustomModel/PBS_to_RandomFlip_attack/MCC_PBS_to_RandomFlip_attack.png\n",
      "Plot saved as CustomModel/PBS_to_RandomFlip_attack/ACC_PBS_to_RandomFlip_attack.png\n",
      "Plot saved as CustomModel/PBS_to_RandomFlip_attack/TPR_PBS_to_RandomFlip_attack.png\n",
      "Plot saved as CustomModel/PBS_to_RandomFlip_attack/F1_PBS_to_RandomFlip_attack.png\n",
      "[Combined Plot] Saved as CustomModel/PBS_to_RandomFlip_attack/combined_metrics_PBS_to_RandomFlip_attack.png\n",
      "MCC after 100 times PBS to Random: 0.06322390407759446\n",
      "Accuracy after 100 times PBS to Random: 0.018974391911110295\n",
      "TPR after 100 times PBS to Random: 0.047350825286084974\n",
      "F1-score after 100 times PBS to Random: 0.012178777997658867\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Tải mô hình đã huấn luyện\n",
    "model_path = os.path.join(\"CustomModel\", \"best_model.pth\")\n",
    "trained_model = CustomModel()\n",
    "\n",
    "# Tải trọng số từ file best_model.pth\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel\", \"PBS_to_RandomFlip_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_paths = [os.path.join(attack_dir, f\"{metric}_PBS_to_RandomFlip_attack.png\") \n",
    "                      for metric in [\"MCC\", \"ACC\", \"TPR\", \"F1\"]]\n",
    "# attack_image_path = os.path.join(attack_dir, \"PBS_to_RandomFlip_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"PBS_to_RandomFlip_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_paths,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path,\n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 3,                  # Chế độ tấn công PBS -> random\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "# best_mcc = validate_score( trained_model,test_loader)\n",
    "# print(f\"\\nMCC after 100 times PBS to Random: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC after 100 times PBS to Random: {results['MCC']}\")\n",
    "print(f\"Accuracy after 100 times PBS to Random: {results['Accuracy']}\")\n",
    "print(f\"TPR after 100 times PBS to Random: {results['TPR']}\")\n",
    "print(f\"F1-score after 100 times PBS to Random: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "799e64b0-3b50-4bfa-9193-95cda8da9a48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.746. Val_Loss: 0.470\n",
      "ACC: 0.763.\n",
      "TPR: 0.700.\n",
      "F1-score: 0.684.\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: stage_2.8.conv_a\n",
      "attacked weight index: 7926\n",
      "weight before attack: tensor(-0.0536, device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "attacked module: fc1\n",
      "Iteration: [001/025]   Attack Time 12.466 (12.466)\n",
      "Loss before attack: 0.3041\n",
      "Loss after attack: 12.3551\n",
      "Bit flips: 2\n",
      "Hamming distance: 2\n",
      "**Test** MCC: 0.028. Val_Loss: 12.955\n",
      "ACC: 0.017.\n",
      "TPR: 0.052.\n",
      "F1-score: 0.028.\n",
      "Iteration Time 6.103 (6.103)\n",
      "**********************************\n",
      "attacked module: stage_3.1.conv_a\n",
      "attacked weight index: 2071\n",
      "weight before attack: tensor(0.2600, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "attacked module: stage_2.1.conv_a\n",
      "Iteration: [002/025]   Attack Time 13.329 (12.897)\n",
      "Loss before attack: 12.3625\n",
      "Loss after attack: 334.8535\n",
      "Bit flips: 4\n",
      "Hamming distance: 4\n",
      "**Test** MCC: -0.016. Val_Loss: 354.133\n",
      "ACC: 0.024.\n",
      "TPR: 0.045.\n",
      "F1-score: 0.021.\n",
      "Iteration Time 6.183 (6.143)\n",
      "**********************************\n",
      "attacked module: stage_2.12.conv_a\n",
      "attacked weight index: 6756\n",
      "weight before attack: tensor(-0.0528, device='cuda:0')\n",
      "weight after attack: tensor(-3., device='cuda:0')\n",
      "attacked module: stage_2.1.conv_b\n",
      "Iteration: [003/025]   Attack Time 13.363 (13.053)\n",
      "Loss before attack: 334.8535\n",
      "Loss after attack: 84902.6953\n",
      "Bit flips: 6\n",
      "Hamming distance: 6\n",
      "**Test** MCC: -0.017. Val_Loss: 89789.669\n",
      "ACC: 0.024.\n",
      "TPR: 0.045.\n",
      "F1-score: 0.021.\n",
      "Iteration Time 6.084 (6.123)\n",
      "**********************************\n",
      "attacked module: stage_2.4.conv_a\n",
      "attacked weight index: 9290\n",
      "weight before attack: tensor(0.0669, device='cuda:0')\n",
      "weight after attack: tensor(-128., device='cuda:0')\n",
      "attacked module: stage_2.2.conv_b\n",
      "Iteration: [004/025]   Attack Time 13.204 (13.091)\n",
      "Loss before attack: 84902.6953\n",
      "Loss after attack: 1379000.5000\n",
      "Bit flips: 8\n",
      "Hamming distance: 8\n",
      "**Test** MCC: -0.018. Val_Loss: 1458337.304\n",
      "ACC: 0.024.\n",
      "TPR: 0.045.\n",
      "F1-score: 0.021.\n",
      "Iteration Time 6.104 (6.118)\n",
      "**********************************\n",
      "attacked module: stage_3.9.conv_b\n",
      "attacked weight index: 37492\n",
      "weight before attack: tensor(-0.1291, device='cuda:0')\n",
      "weight after attack: tensor(-2., device='cuda:0')\n",
      "attacked module: stage_2.2.conv_a\n",
      "Iteration: [005/025]   Attack Time 13.420 (13.157)\n",
      "Loss before attack: 1379000.5000\n",
      "Loss after attack: 242057696.0000\n",
      "Bit flips: 10\n",
      "Hamming distance: 10\n",
      "**Test** MCC: 0.005. Val_Loss: 255985285.769\n",
      "ACC: 0.029.\n",
      "TPR: 0.047.\n",
      "F1-score: 0.004.\n",
      "Iteration Time 6.854 (6.265)\n",
      "**********************************\n",
      "attacked module: stage_3.9.conv_b\n",
      "attacked weight index: 18587\n",
      "weight before attack: tensor(0.0619, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [006/025]   Attack Time 12.629 (13.069)\n",
      "Loss before attack: 242057696.0000\n",
      "Loss after attack: 2827379712.0000\n",
      "Bit flips: 12\n",
      "Hamming distance: 11\n",
      "**Test** MCC: 0.008. Val_Loss: 2936065310.913\n",
      "ACC: 0.029.\n",
      "TPR: 0.049.\n",
      "F1-score: 0.006.\n",
      "Iteration Time 6.294 (6.270)\n",
      "**********************************\n",
      "attacked module: stage_3.13.conv_b\n",
      "attacked weight index: 23906\n",
      "weight before attack: tensor(-0.0736, device='cuda:0')\n",
      "weight after attack: tensor(-17., device='cuda:0')\n",
      "attacked module: stage_2.5.conv_b\n",
      "Iteration: [007/025]   Attack Time 13.055 (13.067)\n",
      "Loss before attack: 2827379712.0000\n",
      "Loss after attack: 23596490752.0000\n",
      "Bit flips: 14\n",
      "Hamming distance: 13\n",
      "**Test** MCC: 0.008. Val_Loss: 24500844032.587\n",
      "ACC: 0.029.\n",
      "TPR: 0.049.\n",
      "F1-score: 0.006.\n",
      "Iteration Time 6.078 (6.243)\n",
      "**********************************\n",
      "attacked module: stage_1.15.conv_b\n",
      "attacked weight index: 75\n",
      "weight before attack: tensor(0.0864, device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "attacked module: stage_2.5.conv_a\n",
      "Iteration: [008/025]   Attack Time 13.206 (13.084)\n",
      "Loss before attack: 23596490752.0000\n",
      "Loss after attack: 3611935637504.0000\n",
      "Bit flips: 16\n",
      "Hamming distance: 15\n",
      "**Test** MCC: 0.006. Val_Loss: 3750476559670.942\n",
      "ACC: 0.029.\n",
      "TPR: 0.049.\n",
      "F1-score: 0.006.\n",
      "Iteration Time 6.227 (6.241)\n",
      "**********************************\n",
      "attacked module: stage_2.10.conv_a\n",
      "attacked weight index: 10633\n",
      "weight before attack: tensor(0.1525, device='cuda:0')\n",
      "weight after attack: tensor(-128., device='cuda:0')\n",
      "attacked module: stage_2.12.conv_b\n",
      "Iteration: [009/025]   Attack Time 13.365 (13.115)\n",
      "Loss before attack: 3611935637504.0000\n",
      "Loss after attack: 27309331447808.0000\n",
      "Bit flips: 18\n",
      "Hamming distance: 17\n",
      "**Test** MCC: 0.005. Val_Loss: 28332757247300.809\n",
      "ACC: 0.029.\n",
      "TPR: 0.048.\n",
      "F1-score: 0.005.\n",
      "Iteration Time 6.360 (6.254)\n",
      "**********************************\n",
      "attacked module: stage_1.7.conv_b\n",
      "attacked weight index: 1548\n",
      "weight before attack: tensor(0.1059, device='cuda:0')\n",
      "weight after attack: tensor(4., device='cuda:0')\n",
      "attacked module: stage_2.12.conv_a\n",
      "Iteration: [010/025]   Attack Time 13.466 (13.150)\n",
      "Loss before attack: 27309331447808.0000\n",
      "Loss after attack: 3675933659627520.0000\n",
      "Bit flips: 20\n",
      "Hamming distance: 19\n",
      "**Test** MCC: 0.006. Val_Loss: 3813678655841004.500\n",
      "ACC: 0.029.\n",
      "TPR: 0.049.\n",
      "F1-score: 0.006.\n",
      "Iteration Time 6.247 (6.253)\n",
      "**********************************\n",
      "attacked module: stage_2.8.conv_b\n",
      "attacked weight index: 3745\n",
      "weight before attack: tensor(0.0200, device='cuda:0')\n",
      "weight after attack: tensor(1., device='cuda:0')\n",
      "attacked module: stage_2.3.conv_b\n",
      "Iteration: [011/025]   Attack Time 13.360 (13.169)\n",
      "Loss before attack: 3674619399634944.0000\n",
      "Loss after attack: 25034382968356864.0000\n",
      "Bit flips: 22\n",
      "Hamming distance: 21\n",
      "**Test** MCC: 0.002. Val_Loss: 25971117505580004.000\n",
      "ACC: 0.028.\n",
      "TPR: 0.047.\n",
      "F1-score: 0.004.\n",
      "Iteration Time 6.383 (6.265)\n",
      "**********************************\n",
      "attacked module: stage_3.8.conv_a\n",
      "attacked weight index: 32381\n",
      "weight before attack: tensor(-0.0730, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "attacked module: stage_2.3.conv_a\n",
      "Iteration: [012/025]   Attack Time 13.400 (13.189)\n",
      "Loss before attack: 25034382968356864.0000\n",
      "Loss after attack: 7579991380445888512.0000\n",
      "Bit flips: 24\n",
      "Hamming distance: 23\n",
      "**Test** MCC: 0.007. Val_Loss: 7863322962918420480.000\n",
      "ACC: 0.029.\n",
      "TPR: 0.049.\n",
      "F1-score: 0.006.\n",
      "Iteration Time 6.135 (6.254)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 877\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(256., device='cuda:0')\n",
      "attacked module: stage_3.9.conv_b\n",
      "Iteration: [013/025]   Attack Time 16.188 (13.419)\n",
      "Loss before attack: 114215279976347860992.0000\n",
      "Loss after attack: 3855321097709302054912.0000\n",
      "Bit flips: 26\n",
      "Hamming distance: 24\n",
      "**Test** MCC: 0.001. Val_Loss: 3952174415237566431232.000\n",
      "ACC: 0.124.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.010.\n",
      "Iteration Time 6.163 (6.247)\n",
      "**********************************\n",
      "attacked module: stage_2.2.conv_b\n",
      "attacked weight index: 1117\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "attacked module: stage_3.9.conv_a\n",
      "Iteration: [014/025]   Attack Time 16.470 (13.637)\n",
      "Loss before attack: 3855321097709302054912.0000\n",
      "Loss after attack: 199170252368579427041280.0000\n",
      "Bit flips: 28\n",
      "Hamming distance: 26\n",
      "**Test** MCC: 0.001. Val_Loss: 204167473257952002965504.000\n",
      "ACC: 0.124.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.010.\n",
      "Iteration Time 6.365 (6.256)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 1719\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "attacked module: stage_3.8.conv_b\n",
      "Iteration: [015/025]   Attack Time 16.251 (13.811)\n",
      "Loss before attack: 199376048857151749226496.0000\n",
      "Loss after attack: 1489552678443458762899456.0000\n",
      "Bit flips: 30\n",
      "Hamming distance: 27\n",
      "**Test** MCC: 0.000. Val_Loss: 1526402052052352143196160.000\n",
      "ACC: 0.124.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.010.\n",
      "Iteration Time 6.148 (6.249)\n",
      "**********************************\n",
      "attacked module: stage_1.13.conv_b\n",
      "attacked weight index: 756\n",
      "weight before attack: tensor(-0.0073, device='cuda:0')\n",
      "weight after attack: tensor(-17., device='cuda:0')\n",
      "attacked module: stage_3.8.conv_a\n",
      "Iteration: [016/025]   Attack Time 16.729 (13.994)\n",
      "Loss before attack: 1489552678443458762899456.0000\n",
      "Loss after attack: 124237714531789407560663040.0000\n",
      "Bit flips: 32\n",
      "Hamming distance: 29\n",
      "**Test** MCC: 0.001. Val_Loss: 127314904583271947524112384.000\n",
      "ACC: 0.124.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.010.\n",
      "Iteration Time 6.239 (6.248)\n",
      "**********************************\n",
      "attacked module: stage_2.5.conv_a\n",
      "attacked weight index: 2469\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-2., device='cuda:0')\n",
      "attacked module: stage_3.5.conv_b\n",
      "Iteration: [017/025]   Attack Time 16.337 (14.132)\n",
      "Loss before attack: 124237714531789407560663040.0000\n",
      "Loss after attack: 754680207035777284189454336.0000\n",
      "Bit flips: 34\n",
      "Hamming distance: 31\n",
      "**Test** MCC: 0.000. Val_Loss: 773391769547253703401013248.000\n",
      "ACC: 0.124.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.010.\n",
      "Iteration Time 6.252 (6.248)\n",
      "**********************************\n",
      "attacked module: stage_3.8.conv_b\n",
      "attacked weight index: 10879\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(64., device='cuda:0')\n",
      "attacked module: stage_3.5.conv_a\n",
      "Iteration: [018/025]   Attack Time 16.329 (14.254)\n",
      "Loss before attack: 754680207035777284189454336.0000\n",
      "Loss after attack: 39994883445577811247513993216.0000\n",
      "Bit flips: 36\n",
      "Hamming distance: 33\n",
      "**Test** MCC: 0.001. Val_Loss: 40988555776792814770628591616.000\n",
      "ACC: 0.124.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.010.\n",
      "Iteration Time 6.376 (6.255)\n",
      "**********************************\n",
      "attacked module: stage_2.15.conv_b\n",
      "attacked weight index: 1482\n",
      "weight before attack: tensor(0.1152, device='cuda:0')\n",
      "weight after attack: tensor(-128., device='cuda:0')\n",
      "attacked module: stage_2.8.conv_b\n",
      "Iteration: [019/025]   Attack Time 13.835 (14.232)\n",
      "Loss before attack: 39994883445577811247513993216.0000\n",
      "Loss after attack: 226145441710298829136708239360.0000\n",
      "Bit flips: 38\n",
      "Hamming distance: 35\n",
      "**Test** MCC: 0.001. Val_Loss: 231766373866894629701754552320.000\n",
      "ACC: 0.124.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.010.\n",
      "Iteration Time 6.581 (6.272)\n",
      "**********************************\n",
      "attacked module: stage_3.14.conv_a\n",
      "attacked weight index: 9823\n",
      "weight before attack: tensor(-0.0759, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "attacked module: stage_2.8.conv_a\n",
      "Iteration: [020/025]   Attack Time 13.227 (14.181)\n",
      "Loss before attack: 227317929750131636128945537024.0000\n",
      "Loss after attack: 36007920819215989158598886293504.0000\n",
      "Bit flips: 40\n",
      "Hamming distance: 37\n",
      "**Test** MCC: 0.001. Val_Loss: 36906210684354120373947051540480.000\n",
      "ACC: 0.124.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.010.\n",
      "Iteration Time 6.247 (6.271)\n",
      "**********************************\n",
      "attacked module: stage_1.9.conv_b\n",
      "attacked weight index: 2467\n",
      "weight before attack: tensor(-0.0469, device='cuda:0')\n",
      "weight after attack: tensor(-33., device='cuda:0')\n",
      "attacked module: stage_3.7.conv_b\n",
      "Iteration: [021/025]   Attack Time 16.208 (14.278)\n",
      "Loss before attack: 36007920819215989158598886293504.0000\n",
      "Loss after attack: 202372402664682451111668694908928.0000\n",
      "Bit flips: 42\n",
      "Hamming distance: 39\n",
      "**Test** MCC: 0.000. Val_Loss: 207414295892641870076505036423168.000\n",
      "ACC: 0.124.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.010.\n",
      "Iteration Time 6.249 (6.270)\n",
      "**********************************\n",
      "attacked module: stage_1.12.conv_b\n",
      "attacked weight index: 2622\n",
      "weight before attack: tensor(0.1473, device='cuda:0')\n",
      "weight after attack: tensor(1., device='cuda:0')\n",
      "attacked module: stage_3.7.conv_a\n",
      "Iteration: [022/025]   Attack Time 16.480 (14.378)\n",
      "Loss before attack: 202372402664682451111668694908928.0000\n",
      "Loss after attack: 41384607860118905373538200615649280.0000\n",
      "Bit flips: 44\n",
      "Hamming distance: 41\n",
      "**Test** MCC: -0.000. Val_Loss: 42416552405324636936721983839666176.000\n",
      "ACC: 0.124.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.010.\n",
      "Iteration Time 6.314 (6.272)\n",
      "**********************************\n",
      "attacked module: stage_1.15.conv_a\n",
      "attacked weight index: 2036\n",
      "weight before attack: tensor(0.1842, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "attacked module: stage_2.15.conv_b\n",
      "Iteration: [023/025]   Attack Time 13.880 (14.356)\n",
      "Loss before attack: 41384607860118905373538200615649280.0000\n",
      "Loss after attack: 226744702476904650177884099117580288.0000\n",
      "Bit flips: 46\n",
      "Hamming distance: 43\n",
      "**Test** MCC: 0.000. Val_Loss: 232387024798499766383541678287880192.000\n",
      "ACC: 0.124.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.010.\n",
      "Iteration Time 6.482 (6.281)\n",
      "**********************************\n",
      "attacked module: stage_3.12.conv_b\n",
      "attacked weight index: 20955\n",
      "weight before attack: tensor(0.0567, device='cuda:0')\n",
      "weight after attack: tensor(32., device='cuda:0')\n",
      "attacked module: stage_2.14.conv_a\n",
      "Iteration: [024/025]   Attack Time 13.282 (14.312)\n",
      "Loss before attack: 226744702476904650177884099117580288.0000\n",
      "Loss after attack: inf\n",
      "Bit flips: 48\n",
      "Hamming distance: 45\n",
      "**Test** MCC: 0.000. Val_Loss: inf\n",
      "ACC: 0.124.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.010.\n",
      "Iteration Time 6.199 (6.278)\n",
      "**********************************\n",
      "attacked module: stage_1.1.conv_b\n",
      "attacked weight index: 3015\n",
      "weight before attack: tensor(0.0090, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "attacked module: fc1\n",
      "Iteration: [025/025]   Attack Time 19.428 (14.516)\n",
      "Loss before attack: inf\n",
      "Loss after attack: nan\n",
      "Bit flips: 57\n",
      "Hamming distance: 54\n",
      "**Test** MCC: 0.000. Val_Loss: nan\n",
      "ACC: 0.124.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.010.\n",
      "Iteration Time 6.275 (6.278)\n",
      "Plot saved as CustomModel/RandomFlip_to_PBS_attack/MCC_RandomFlip_to_PBS_attack.png\n",
      "Plot saved as CustomModel/RandomFlip_to_PBS_attack/ACC_RandomFlip_to_PBS_attack.png\n",
      "Plot saved as CustomModel/RandomFlip_to_PBS_attack/TPR_RandomFlip_to_PBS_attack.png\n",
      "Plot saved as CustomModel/RandomFlip_to_PBS_attack/F1_RandomFlip_to_PBS_attack.png\n",
      "[Combined Plot] Saved as CustomModel/RandomFlip_to_PBS_attack/combined_metrics_RandomFlip_to_PBS_attack.png\n",
      "MCC after 100 times random to PBS: 0.0004572154545481975\n",
      "Accuracy after 100 times random to PBS: 0.12368220646120251\n",
      "TPR after 100 times random to PBS: 0.0463077387308477\n",
      "F1-score after 100 times random to PBS: 0.010194952333404853\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Tải mô hình đã huấn luyện\n",
    "model_path = os.path.join(\"CustomModel\", \"best_model.pth\")\n",
    "trained_model = CustomModel()\n",
    "\n",
    "# Tải trọng số từ file best_model.pth\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel\", \"RandomFlip_to_PBS_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_paths = [os.path.join(attack_dir, f\"{metric}_RandomFlip_to_PBS_attack.png\") \n",
    "                      for metric in [\"MCC\", \"ACC\", \"TPR\", \"F1\"]]\n",
    "# attack_image_path = os.path.join(attack_dir, \"RandomFlip_to_PBS_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"RandomFlip_to_PBS_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_paths,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path,  \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 4,                  # Chế độ tấn công Random -> PBS\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "# best_mcc = validate_score( trained_model,test_loader)\n",
    "# print(f\"\\nMCC after 100 times random to PBS: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC after 100 times random to PBS: {results['MCC']}\")\n",
    "print(f\"Accuracy after 100 times random to PBS: {results['Accuracy']}\")\n",
    "print(f\"TPR after 100 times random to PBS: {results['TPR']}\")\n",
    "print(f\"F1-score after 100 times random to PBS: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000339bd",
   "metadata": {},
   "source": [
    "## 📊 Hướng dẫn: Thêm tracking history vào training loop\n",
    "\n",
    "**QUAN TRỌNG:** Bạn cần thêm đoạn code sau vào cell training loop (ngay sau dòng `scheduler.step(val_loss)`):\n",
    "\n",
    "```python\n",
    "# Training history for visualization (thêm vào đầu training loop)\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_mcc': [],\n",
    "    'val_loss': [],\n",
    "    'val_mcc': [],\n",
    "    'val_acc': [],\n",
    "    'val_tpr': [],\n",
    "    'val_f1': []\n",
    "}\n",
    "\n",
    "# Trong vòng lặp for epoch, thêm sau scheduler.step(val_loss):\n",
    "    # Store history for visualization\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_mcc'].append(train_mcc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_mcc'].append(val_mcc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_tpr'].append(val_tpr)\n",
    "    history['val_f1'].append(val_f1)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ce159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Hàm vẽ biểu đồ training history và confusion matrix\n",
    "# ============================================================================\n",
    "\n",
    "def plot_training_history(history, save_dir, model_name=\"CustomModel\", dataset_name=\"CIC2023\"):\n",
    "    \"\"\"\n",
    "    Plot training history including loss, accuracy, MCC, TPR, F1\n",
    "    \n",
    "    Args:\n",
    "        history: Dictionary containing training history\n",
    "        save_dir: Directory to save plots\n",
    "        model_name: Name of the model\n",
    "        dataset_name: Name of the dataset\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams['figure.figsize'] = (12, 8)\n",
    "    \n",
    "    # 1. Plot Loss Curves\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2, marker='o')\n",
    "    plt.plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2, marker='s')\n",
    "    plt.title(f'Training and Validation Loss - {model_name} on {dataset_name}', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    loss_path = os.path.join(save_dir, f'{model_name}_loss_curves.png')\n",
    "    plt.savefig(loss_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Loss curves saved to: {loss_path}\")\n",
    "    \n",
    "    # 2. Plot MCC Curves\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, history['train_mcc'], 'b-', label='Training MCC', linewidth=2, marker='o')\n",
    "    plt.plot(epochs, history['val_mcc'], 'r-', label='Validation MCC', linewidth=2, marker='s')\n",
    "    plt.title(f'Training and Validation MCC - {model_name} on {dataset_name}', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('MCC', fontsize=12)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    mcc_path = os.path.join(save_dir, f'{model_name}_mcc_curves.png')\n",
    "    plt.savefig(mcc_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"MCC curves saved to: {mcc_path}\")\n",
    "    \n",
    "    # 3. Plot Metrics (MCC, TPR, F1, Accuracy)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(epochs, history['val_mcc'], 'g-', label='MCC', linewidth=2, marker='o')\n",
    "    plt.plot(epochs, history['val_acc'], 'm-', label='Accuracy', linewidth=2, marker='s')\n",
    "    plt.plot(epochs, history['val_tpr'], 'c-', label='TPR (Recall)', linewidth=2, marker='^')\n",
    "    plt.plot(epochs, history['val_f1'], 'orange', label='F1 Score', linewidth=2, marker='d')\n",
    "    plt.title(f'Validation Metrics - {model_name} on {dataset_name}', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Metric Value', fontsize=12)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    metrics_path = os.path.join(save_dir, f'{model_name}_metrics_curves.png')\n",
    "    plt.savefig(metrics_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Metrics curves saved to: {metrics_path}\")\n",
    "    \n",
    "    # 4. Combined Loss and MCC\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    ax1.plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2, marker='o')\n",
    "    ax1.plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2, marker='s')\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.set_title('Loss Convergence', fontsize=13, fontweight='bold')\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    ax2.plot(epochs, history['train_mcc'], 'b-', label='Training MCC', linewidth=2, marker='o')\n",
    "    ax2.plot(epochs, history['val_mcc'], 'r-', label='Validation MCC', linewidth=2, marker='s')\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('MCC', fontsize=12)\n",
    "    ax2.set_title('MCC Convergence', fontsize=13, fontweight='bold')\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.suptitle(f'Model Convergence - {model_name} on {dataset_name}', fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    combined_path = os.path.join(save_dir, f'{model_name}_convergence.png')\n",
    "    plt.savefig(combined_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Convergence plot saved to: {combined_path}\")\n",
    "\n",
    "def plot_confusion_matrix(cm, num_classes, save_dir, model_name=\"CustomModel\", dataset_name=\"CIC2023\", class_names=None):\n",
    "    \"\"\"\n",
    "    Plot and save confusion matrix\n",
    "    \n",
    "    Args:\n",
    "        cm: Confusion matrix (numpy array)\n",
    "        num_classes: Number of classes\n",
    "        save_dir: Directory to save plot\n",
    "        model_name: Name of the model\n",
    "        dataset_name: Name of the dataset\n",
    "        class_names: Optional list of class names\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Convert to numpy if it's a list\n",
    "    if isinstance(cm, list):\n",
    "        cm = np.array(cm)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Normalize confusion matrix for better visualization\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_normalized = np.nan_to_num(cm_normalized)  # Handle division by zero\n",
    "    \n",
    "    # Create labels for classes\n",
    "    if class_names is None:\n",
    "        class_names = [f'Class {i}' for i in range(num_classes)]\n",
    "    \n",
    "    # Plot heatmap\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Normalized Frequency'}, linewidths=0.5)\n",
    "    \n",
    "    plt.title(f'Confusion Matrix - {model_name} on {dataset_name}', fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    cm_path = os.path.join(save_dir, f'{model_name}_confusion_matrix.png')\n",
    "    plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Confusion matrix saved to: {cm_path}\")\n",
    "    \n",
    "    # Also save raw confusion matrix (non-normalized)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count'}, linewidths=0.5)\n",
    "    \n",
    "    plt.title(f'Confusion Matrix (Raw Counts) - {model_name} on {dataset_name}', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    cm_raw_path = os.path.join(save_dir, f'{model_name}_confusion_matrix_raw.png')\n",
    "    plt.savefig(cm_raw_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Raw confusion matrix saved to: {cm_raw_path}\")\n",
    "\n",
    "print(\"Visualization functions loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7697a5c3-03a5-41bf-ab93-fb316b41e52f",
   "metadata": {},
   "source": [
    "## Train CustomModel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c6b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Vẽ biểu đồ sau khi training hoàn tất\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING VISUALIZATION PLOTS...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "save_dir = \"CustomModel\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history, save_dir, model_name=\"CustomModel\", dataset_name=\"CIC2023\")\n",
    "\n",
    "# Calculate and plot confusion matrix from final validation\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (input, target) in enumerate(test_loader):\n",
    "        if input.size(1) == 39 and input.dim() == 2:\n",
    "            input = input.unsqueeze(-1)\n",
    "        \n",
    "        if torch.cuda.is_available() and args.use_cuda:\n",
    "            target = target.cuda(non_blocking=True)\n",
    "            input = input.cuda(non_blocking=True)\n",
    "        \n",
    "        output = model(input)\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        \n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(all_targets, all_predictions)\n",
    "num_classes = len(np.unique(all_targets))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(cm, num_classes, save_dir, model_name=\"CustomModel\", dataset_name=\"CIC2023\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"All visualization plots have been saved successfully!\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb16fd3-7699-4cb4-8d3a-6e981aeffaf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CustomModel2().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 10  # Số epoch để chờ trước khi dừng\n",
    "counter = 0\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "# Vòng lặp huấn luyện\n",
    "best_val_loss = float('inf')\n",
    "best_mcc = -1  # Khởi tạo MCC tốt nhất\n",
    "\n",
    "# Vòng lặp huấn luyện\n",
    "for epoch in range(num_epochs):\n",
    "    train_mcc, train_loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    val_mcc, val_loss, output_summary = validate(test_loader, model, criterion, summary_output=True)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_mcc = val_mcc  # Lưu MCC tốt nhất\n",
    "        counter = 0\n",
    "\n",
    "        save_dir = \"CustomModel2\"\n",
    "        save_path = os.path.join(save_dir, \"model.pth\")\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train MCC: {train_mcc:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation MCC: {val_mcc:.4f}\")\n",
    "print(f\"Best MCC during training: {best_mcc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1da615-4cac-4211-aa06-e9fa9f329505",
   "metadata": {},
   "source": [
    "## Attack second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5dcfa057-0619-4fa5-aed2-8b01848a50f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Không tìm thấy mô hình tại: CustomModel2/model.pth",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m model_path = os.path.join(\u001b[33m\"\u001b[39m\u001b[33mCustomModel2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel.pth\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(model_path):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKhông tìm thấy mô hình tại: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m trained_model = CustomModel2()\n\u001b[32m      7\u001b[39m trained_model.load_state_dict(torch.load(model_path, map_location=torch.device(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)))\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Không tìm thấy mô hình tại: CustomModel2/model.pth"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"CustomModel2\", \"model.pth\")\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Không tìm thấy mô hình tại: {model_path}\")\n",
    "\n",
    "trained_model = CustomModel2()\n",
    "\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# best_mcc = validate_score(trained_model, test_loader)\n",
    "# print(f\"MCC before attack: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC before attack: {results['MCC']}\")\n",
    "print(f\"Accuracy before attack: {results['Accuracy']}\")\n",
    "print(f\"TPR before attack: {results['TPR']}\")\n",
    "print(f\"F1-score before attack: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35349df9-2ad5-4463-ab65-d64b1f095f08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join(\"CustomModel2\", \"model.pth\")\n",
    "\n",
    "trained_model = CustomModel2()\n",
    "\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel2\", \"PBS_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_paths = [os.path.join(attack_dir, f\"{metric}_PBS_attack.png\") \n",
    "                      for metric in [\"MCC\", \"ACC\", \"TPR\", \"F1\"]]\n",
    "# attack_image_path = os.path.join(attack_dir, \"PBS_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"PBS_attack.csv\")\n",
    "\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_paths,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path,  \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 1,                  # Chế độ tấn công PBS\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "# best_mcc = validate_score(trained_model, test_loader)\n",
    "# print(f\"\\nMCC after 100 times PBS: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC after 100 times PBS attack: {results['MCC']}\")\n",
    "print(f\"Accuracy after 100 times PBS attack: {results['Accuracy']}\")\n",
    "print(f\"TPR after 100 times PBS attack: {results['TPR']}\")\n",
    "print(f\"F1-score after 100 times PBS attack: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a700d594-b183-473f-9a0f-03aec9ccfdb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join(\"CustomModel2\", \"model.pth\")\n",
    "trained_model = CustomModel2()\n",
    "\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel2\", \"RandomFlip_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_paths = [os.path.join(attack_dir, f\"{metric}_RandomFlip_attack.png\") \n",
    "                      for metric in [\"MCC\", \"ACC\", \"TPR\", \"F1\"]]\n",
    "# attack_image_path = os.path.join(attack_dir, \"RandomFlip_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"RandomFlip_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_paths,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path, \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 2,                  # Chế độ tấn công random\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "\n",
    "# best_mcc = validate_score(trained_model ,test_loader)\n",
    "# print(f\"\\nMCC after 100 times Random attack: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC after 100 times random attack: {results['MCC']}\")\n",
    "print(f\"Accuracy after 100 times random attack: {results['Accuracy']}\")\n",
    "print(f\"TPR after 100 times random attack: {results['TPR']}\")\n",
    "print(f\"F1-score after 100 times random attack: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c7df1b-f79c-407c-a2a7-0b26256de0e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join(\"CustomModel2\", \"model.pth\")\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Không tìm thấy mô hình tại: {model_path}\")\n",
    "\n",
    "trained_model = CustomModel2()\n",
    "\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel2\", \"PBS_to_RandomFlip_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_paths = [os.path.join(attack_dir, f\"{metric}_PBS_to_RandomFlip_attack.png\") \n",
    "                      for metric in [\"MCC\", \"ACC\", \"TPR\", \"F1\"]]\n",
    "# attack_image_path = os.path.join(attack_dir, \"PBS_to_RandomFlip_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"PBS_to_RandomFlip_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_paths,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path, \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 3,                  # Chế độ tấn công PBS -> random\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "# best_mcc = validate_score( trained_model,test_loader)\n",
    "# print(f\"\\nMCC after 100 times PBS to Random: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC after 100 times PBS to Random: {results['MCC']}\")\n",
    "print(f\"Accuracy after 100 times PBS to Random: {results['Accuracy']}\")\n",
    "print(f\"TPR after 100 times PBS to Random: {results['TPR']}\")\n",
    "print(f\"F1-score after 100 times PBS to Random: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d875038-92fb-44a5-80f3-36ddbb14431b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bước 1: Tải mô hình đã huấn luyện\n",
    "model_path = os.path.join(\"CustomModel2\", \"model.pth\")\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Không tìm thấy mô hình tại: {model_path}\")\n",
    "\n",
    "trained_model = CustomModel2()\n",
    "\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel2\", \"RandomFlip_to_PBS_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_paths = [os.path.join(attack_dir, f\"{metric}_RandomFlip_to_PBS_attack.png\") \n",
    "                      for metric in [\"MCC\", \"ACC\", \"TPR\", \"F1\"]]\n",
    "# attack_image_path = os.path.join(attack_dir, \"RandomFlip_to_PBS_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"RandomFlip_to_PBS_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_paths,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path,  \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 4,                  # Chế độ tấn công Random -> PBS\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "# best_mcc = validate_score( trained_model,test_loader)\n",
    "# print(f\"\\nMCC after 100 times Random to PBS: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC after 100 times random to PBS: {results['MCC']}\")\n",
    "print(f\"Accuracy after 100 times random to PBS: {results['Accuracy']}\")\n",
    "print(f\"TPR after 100 times random to PBS: {results['TPR']}\")\n",
    "print(f\"F1-score after 100 times random to PBS: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199afe5b-0442-41e8-8bd7-f0e17a00340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"CustomModel\", \"CustomModel2\"]\n",
    "attack_types = [\"PBS\", \"RandomFlip\", \"PBS_to_RandomFlip\", \"RandomFlip_to_PBS\"]\n",
    "\n",
    "def aggregate_results(model_name, attack_types):\n",
    "    \n",
    "    aggregate_dir = os.path.join(model_name, \"Aggregate_Results\")\n",
    "    os.makedirs(aggregate_dir, exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Đọc kết quả từ từng kịch bản tấn công\n",
    "    for attack_type in attack_types:\n",
    "        csv_file_path = os.path.join(model_name, f\"{attack_type}_attack\", f\"{attack_type}_attack.csv\")\n",
    "        if os.path.exists(csv_file_path):\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "            \n",
    "            mcc_values = df['MCC'].tolist()\n",
    "            results.append(mcc_values)\n",
    "        else:\n",
    "            print(f\"File {csv_file_path} không tồn tại.\")\n",
    "\n",
    "    # Ghi kết quả tổng hợp vào file CSV\n",
    "    aggregate_df = pd.DataFrame(results, index=attack_types).T\n",
    "    aggregate_csv_path = os.path.join(aggregate_dir, \"aggregated_results.csv\")\n",
    "    aggregate_df.to_csv(aggregate_csv_path)\n",
    "\n",
    "    # Vẽ đồ thị so sánh\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, attack_type in enumerate(attack_types):\n",
    "        plt.plot(aggregate_df.index, aggregate_df[attack_type], marker='o', label=attack_type)\n",
    "\n",
    "    plt.title(f'So sánh MCC giữa các kịch bản tấn công cho {model_name}', fontsize=14)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('MCC', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    epochs = aggregate_df.index.astype(int).tolist()\n",
    "    plt.xticks(epochs, epochs)\n",
    "    \n",
    "    plot_path = os.path.join(aggregate_dir, f\"{model_name}_comparison_plot.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    print(f\"Đồ thị đã được lưu tại {plot_path}\")\n",
    "\n",
    "for model_name in model_names:\n",
    "    aggregate_results(model_name, attack_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cbb54e-7f00-47a5-abd1-35e54fc19f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans, sans-serif'\n",
    "\n",
    "def plot_attack_comparison_separate(model_names, attack_types):\n",
    "    \"\"\"Vẽ biểu đồ riêng biệt cho từng model, so sánh MCC giữa các phương pháp tấn công\"\"\"\n",
    "    \n",
    "    output_dir = \"Comparative_Analysis\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for model_name in model_names:\n",
    "        aggregate_path = os.path.join(model_name, \"Aggregate_Results\", \"aggregated_results.csv\")\n",
    "        if not os.path.exists(aggregate_path):\n",
    "            print(f\"Không tìm thấy file tổng hợp cho {model_name}\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(aggregate_path, index_col=0)\n",
    "\n",
    "        # Chuẩn bị dữ liệu để vẽ\n",
    "        df_melted = df.reset_index().melt(\n",
    "            id_vars='index',\n",
    "            value_vars=attack_types,\n",
    "            var_name='Attack Type',\n",
    "            value_name='MCC'\n",
    "        )\n",
    "\n",
    "        # Tạo một figure riêng cho từng model\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.lineplot(\n",
    "            data=df_melted, x='index', y='MCC', hue='Attack Type',\n",
    "            style='Attack Type', markers=True, dashes=False,\n",
    "            linewidth=2.5, markersize=8, errorbar=None\n",
    "        )\n",
    "\n",
    "        # Tùy chỉnh biểu đồ\n",
    "        plt.xlabel('Attack Iteration', fontsize=12)\n",
    "        plt.ylabel('Matthews Correlation Coefficient', fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.legend(title='Attack Strategy', title_fontsize='12', fontsize=10)\n",
    "\n",
    "        plt.xticks(ticks=range(int(df.index.min()), int(df.index.max()) + 1, 2))\n",
    "\n",
    "\n",
    "        # Highlight MCC thấp nhất\n",
    "        min_mcc = df[attack_types].min().min()\n",
    "        plt.axhline(y=min_mcc, color='r', linestyle='--', alpha=0.5)\n",
    "        plt.text(x=0, y=min_mcc + 0.05,\n",
    "                 s=f'Min MCC: {min_mcc:.3f}',\n",
    "                 color='r', fontsize=10)\n",
    "\n",
    "        # Lưu hình\n",
    "        output_path = os.path.join(output_dir, f\"{model_name}_CIC23_attack_comparison.png\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Đã lưu biểu đồ cho {model_name} tại: {output_path}\")\n",
    "\n",
    "# Gọi hàm\n",
    "model_names = [\"CustomModel\", \"CustomModel2\"]\n",
    "attack_types = [\"PBS\", \"RandomFlip\", \"PBS_to_RandomFlip\", \"RandomFlip_to_PBS\"]\n",
    "plot_attack_comparison_separate(model_names, attack_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d442420-1e3a-4c6d-add6-de3d41b1e015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
